{
  "01-ai/Yi-1.5-34B-Chat-16K": {
    "description": "Yi-1.5 34Bは豊富な訓練サンプルを用いて業界アプリケーションで優れたパフォーマンスを提供します。"
  },
  "01-ai/Yi-1.5-6B-Chat": {
    "description": "Yi-1.5-6B-ChatはYi-1.5シリーズの変種で、オープンソースのチャットモデルに属します。Yi-1.5はYiのアップグレード版で、500Bの高品質コーパスで継続的に事前訓練され、3Mの多様な微調整サンプルで微調整されています。Yiと比較して、Yi-1.5はコーディング、数学、推論、指示遵守能力においてより強力な性能を示し、優れた言語理解、常識推論、読解能力を維持しています。このモデルは4K、16K、32Kのコンテキスト長バージョンを持ち、事前訓練の総量は3.6Tトークンに達します。"
  },
  "01-ai/Yi-1.5-9B-Chat-16K": {
    "description": "Yi-1.5 9Bは16Kトークンをサポートし、高効率でスムーズな言語生成能力を提供します。"
  },
  "360gpt-pro": {
    "description": "360GPT Proは360 AIモデルシリーズの重要なメンバーであり、高効率なテキスト処理能力を持ち、多様な自然言語アプリケーションシーンに対応し、長文理解や多輪対話などの機能をサポートします。"
  },
  "360gpt-turbo": {
    "description": "360GPT Turboは強力な計算と対話能力を提供し、優れた意味理解と生成効率を備え、企業や開発者にとって理想的なインテリジェントアシスタントソリューションです。"
  },
  "360gpt-turbo-responsibility-8k": {
    "description": "360GPT Turbo Responsibility 8Kは意味の安全性と責任指向を強調し、コンテンツの安全性に高い要求を持つアプリケーションシーンのために設計されており、ユーザー体験の正確性と堅牢性を確保します。"
  },
  "360gpt2-o1": {
    "description": "360gpt2-o1は、ツリーサーチを使用して思考の連鎖を構築し、反省メカニズムを導入し、強化学習で訓練されたモデルであり、自己反省と誤り訂正の能力を備えています。"
  },
  "360gpt2-pro": {
    "description": "360GPT2 Proは360社が発表した高級自然言語処理モデルで、卓越したテキスト生成と理解能力を備え、特に生成と創作の分野で優れたパフォーマンスを発揮し、複雑な言語変換や役割演技タスクを処理できます。"
  },
  "360zhinao2-o1": {
    "description": "360zhinao2-o1は、木探索を使用して思考の連鎖を構築し、反省メカニズムを導入し、強化学習で訓練され、自己反省と誤り訂正の能力を備えています。"
  },
  "4.0Ultra": {
    "description": "Spark4.0 Ultraは星火大モデルシリーズの中で最も強力なバージョンで、ネットワーク検索のリンクをアップグレードし、テキストコンテンツの理解と要約能力を向上させています。これは、オフィスの生産性を向上させ、要求に正確に応えるための全方位のソリューションであり、業界をリードするインテリジェントな製品です。"
  },
  "Baichuan2-Turbo": {
    "description": "検索強化技術を採用し、大モデルと分野知識、全網知識の全面的なリンクを実現しています。PDF、Wordなどのさまざまな文書のアップロードやURL入力をサポートし、情報取得が迅速かつ包括的で、出力結果は正確かつ専門的です。"
  },
  "Baichuan3-Turbo": {
    "description": "企業の高頻度シーンに最適化され、効果が大幅に向上し、高コストパフォーマンスを実現しています。Baichuan2モデルに対して、コンテンツ生成が20%、知識問答が17%、役割演技能力が40%向上しています。全体的な効果はGPT3.5よりも優れています。"
  },
  "Baichuan3-Turbo-128k": {
    "description": "128Kの超長コンテキストウィンドウを備え、企業の高頻度シーンに最適化され、効果が大幅に向上し、高コストパフォーマンスを実現しています。Baichuan2モデルに対して、コンテンツ生成が20%、知識問答が17%、役割演技能力が40%向上しています。全体的な効果はGPT3.5よりも優れています。"
  },
  "Baichuan4": {
    "description": "モデル能力は国内でトップであり、知識百科、長文、生成創作などの中国語タスクで海外の主流モデルを超えています。また、業界をリードするマルチモーダル能力を備え、複数の権威ある評価基準で優れたパフォーマンスを示しています。"
  },
  "Baichuan4-Air": {
    "description": "モデル能力は国内で第一であり、知識百科、長文、生成創作などの中国語タスクで海外の主流モデルを超えています。また、業界をリードするマルチモーダル能力を持ち、多くの権威ある評価基準で優れたパフォーマンスを示しています。"
  },
  "Baichuan4-Turbo": {
    "description": "モデル能力は国内で第一であり、知識百科、長文、生成創作などの中国語タスクで海外の主流モデルを超えています。また、業界をリードするマルチモーダル能力を持ち、多くの権威ある評価基準で優れたパフォーマンスを示しています。"
  },
  "DeepSeek-R1": {
    "description": "最先端の効率的なLLMで、推論、数学、プログラミングに優れています。"
  },
  "DeepSeek-R1-Distill-Llama-70B": {
    "description": "DeepSeek R1——DeepSeekスイートの中でより大きく、より賢いモデル——がLlama 70Bアーキテクチャに蒸留されました。ベンチマークテストと人間の評価に基づき、このモデルは元のLlama 70Bよりも賢く、特に数学と事実の正確性が求められるタスクで優れた性能を発揮します。"
  },
  "DeepSeek-R1-Distill-Qwen-1.5B": {
    "description": "Qwen2.5-Math-1.5Bに基づくDeepSeek-R1蒸留モデルで、強化学習とコールドスタートデータを通じて推論性能を最適化し、オープンソースモデルがマルチタスクの基準を刷新しました。"
  },
  "DeepSeek-R1-Distill-Qwen-14B": {
    "description": "Qwen2.5-14Bに基づくDeepSeek-R1蒸留モデルで、強化学習とコールドスタートデータを通じて推論性能を最適化し、オープンソースモデルがマルチタスクの基準を刷新しました。"
  },
  "DeepSeek-R1-Distill-Qwen-32B": {
    "description": "DeepSeek-R1シリーズは、強化学習とコールドスタートデータを通じて推論性能を最適化し、オープンソースモデルがマルチタスクの基準を刷新し、OpenAI-o1-miniのレベルを超えました。"
  },
  "DeepSeek-R1-Distill-Qwen-7B": {
    "description": "Qwen2.5-Math-7Bに基づくDeepSeek-R1蒸留モデルで、強化学習とコールドスタートデータを通じて推論性能を最適化し、オープンソースモデルがマルチタスクの基準を刷新しました。"
  },
  "Doubao-1.5-vision-pro-32k": {
    "description": "Doubao-1.5-vision-proは全く新しいアップグレード版のマルチモーダル大モデルで、任意の解像度と極端なアスペクト比の画像認識をサポートし、視覚推論、文書認識、詳細情報の理解、指示遵守能力を強化しています。"
  },
  "Doubao-lite-128k": {
    "description": "Doubao-liteは、極めて高速な応答速度と優れたコストパフォーマンスを備え、顧客のさまざまなシーンに柔軟な選択肢を提供します。128kコンテキストウィンドウの推論と微調整をサポートしています。"
  },
  "Doubao-lite-32k": {
    "description": "Doubao-liteは、極めて高速な応答速度と優れたコストパフォーマンスを備え、顧客のさまざまなシーンに柔軟な選択肢を提供します。32kコンテキストウィンドウの推論と微調整をサポートしています。"
  },
  "Doubao-lite-4k": {
    "description": "Doubao-liteは、極めて高速な応答速度と優れたコストパフォーマンスを備え、顧客のさまざまなシーンに柔軟な選択肢を提供します。4kコンテキストウィンドウの推論と微調整をサポートしています。"
  },
  "Doubao-pro-128k": {
    "description": "最も効果的な主力モデルで、複雑なタスクの処理に適しており、参考質問応答、要約、創作、テキスト分類、ロールプレイングなどのシーンで素晴らしい結果を出します。128kコンテキストウィンドウの推論と微調整をサポートしています。"
  },
  "Doubao-pro-256k": {
    "description": "最も効果的な主力モデルで、複雑なタスクの処理に適しており、参考質問応答、要約、創作、テキスト分類、ロールプレイなどのシーンで優れた効果を発揮します。256kのコンテキストウィンドウでの推論とファインチューニングをサポートします。"
  },
  "Doubao-pro-32k": {
    "description": "最も効果的な主力モデルで、複雑なタスクの処理に適しており、参考質問応答、要約、創作、テキスト分類、ロールプレイングなどのシーンで素晴らしい結果を出します。32kコンテキストウィンドウの推論と微調整をサポートしています。"
  },
  "Doubao-pro-4k": {
    "description": "最も効果的な主力モデルで、複雑なタスクの処理に適しており、参考質問応答、要約、創作、テキスト分類、ロールプレイングなどのシーンで素晴らしい結果を出します。4kコンテキストウィンドウの推論と微調整をサポートしています。"
  },
  "Doubao-vision-lite-32k": {
    "description": "Doubao-visionモデルは豆包が提供するマルチモーダル大モデルで、強力な画像理解と推論能力、正確な指示理解能力を備えています。モデルは画像テキスト情報の抽出や画像に基づく推論タスクで強力な性能を発揮し、より複雑で広範な視覚的質問応答タスクに応用できます。"
  },
  "Doubao-vision-pro-32k": {
    "description": "Doubao-visionモデルは豆包が提供するマルチモーダル大モデルで、強力な画像理解と推論能力、正確な指示理解能力を備えています。モデルは画像テキスト情報の抽出や画像に基づく推論タスクで強力な性能を発揮し、より複雑で広範な視覚的質問応答タスクに応用できます。"
  },
  "ERNIE-3.5-128K": {
    "description": "百度が独自に開発したフラッグシップの大規模言語モデルで、膨大な中英語のコーパスをカバーし、強力な汎用能力を持っています。ほとんどの対話型質問応答、創作生成、プラグインアプリケーションの要件を満たすことができます。また、百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。"
  },
  "ERNIE-3.5-8K": {
    "description": "百度が独自に開発したフラッグシップの大規模言語モデルで、膨大な中英語のコーパスをカバーし、強力な汎用能力を持っています。ほとんどの対話型質問応答、創作生成、プラグインアプリケーションの要件を満たすことができます。また、百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。"
  },
  "ERNIE-3.5-8K-Preview": {
    "description": "百度が独自に開発したフラッグシップの大規模言語モデルで、膨大な中英語のコーパスをカバーし、強力な汎用能力を持っています。ほとんどの対話型質問応答、創作生成、プラグインアプリケーションの要件を満たすことができます。また、百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。"
  },
  "ERNIE-4.0-8K-Latest": {
    "description": "百度が独自に開発したフラッグシップの超大規模言語モデルで、ERNIE 3.5に比べてモデル能力が全面的にアップグレードされ、さまざまな分野の複雑なタスクシナリオに広く適用されます。百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。"
  },
  "ERNIE-4.0-8K-Preview": {
    "description": "百度が独自に開発したフラッグシップの超大規模言語モデルで、ERNIE 3.5に比べてモデル能力が全面的にアップグレードされ、さまざまな分野の複雑なタスクシナリオに広く適用されます。百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。"
  },
  "ERNIE-4.0-Turbo-8K-Latest": {
    "description": "百度が自主開発したフラッグシップの超大規模な言語モデルで、総合的なパフォーマンスが優れており、各分野の複雑なタスクシナリオに広く適応します；百度検索プラグインとの自動連携をサポートし、質問応答情報のタイムリーさを保証します。ERNIE 4.0に比べてパフォーマンスが向上しています。"
  },
  "ERNIE-4.0-Turbo-8K-Preview": {
    "description": "百度が独自に開発したフラッグシップの超大規模言語モデルで、総合的なパフォーマンスが優れており、さまざまな分野の複雑なタスクシナリオに広く適用されます。百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。ERNIE 4.0に比べてパフォーマンスがさらに優れています。"
  },
  "ERNIE-Character-8K": {
    "description": "百度が独自に開発した垂直シナリオ向けの大規模言語モデルで、ゲームのNPC、カスタマーサービスの対話、対話型キャラクターの役割演技などのアプリケーションシナリオに適しており、キャラクターのスタイルがより鮮明で一貫性があり、指示に従う能力が強化され、推論性能が向上しています。"
  },
  "ERNIE-Lite-Pro-128K": {
    "description": "百度が独自に開発した軽量大規模言語モデルで、優れたモデル効果と推論性能を兼ね備え、ERNIE Liteよりも効果が優れており、低計算能力のAIアクセラレータカードでの推論使用に適しています。"
  },
  "ERNIE-Speed-128K": {
    "description": "百度が2024年に最新リリースした独自開発の高性能大規模言語モデルで、汎用能力が優れており、基盤モデルとして微調整に適しており、特定のシナリオの問題をより良く処理し、優れた推論性能を持っています。"
  },
  "ERNIE-Speed-Pro-128K": {
    "description": "百度が2024年に最新リリースした独自開発の高性能大規模言語モデルで、汎用能力が優れており、ERNIE Speedよりも効果が優れており、基盤モデルとして微調整に適しており、特定のシナリオの問題をより良く処理し、優れた推論性能を持っています。"
  },
  "Gryphe/MythoMax-L2-13b": {
    "description": "MythoMax-L2 (13B)は、革新的なモデルであり、多分野のアプリケーションや複雑なタスクに適しています。"
  },
  "InternVL2-8B": {
    "description": "InternVL2-8Bは、強力な視覚言語モデルで、画像とテキストのマルチモーダル処理をサポートし、画像内容を正確に認識し、関連する説明や回答を生成することができます。"
  },
  "InternVL2.5-26B": {
    "description": "InternVL2.5-26Bは、強力な視覚言語モデルで、画像とテキストのマルチモーダル処理をサポートし、画像内容を正確に認識し、関連する説明や回答を生成することができます。"
  },
  "Llama-3.2-11B-Vision-Instruct": {
    "description": "高解像度画像で優れた画像推論能力を発揮し、視覚理解アプリケーションに適しています。"
  },
  "Llama-3.2-90B-Vision-Instruct\t": {
    "description": "視覚理解エージェントアプリケーションに適した高度な画像推論能力を備えています。"
  },
  "LoRA/Qwen/Qwen2.5-72B-Instruct": {
    "description": "Qwen2.5-72B-InstructはAlibaba Cloudが発表した最新の大規模言語モデルシリーズの一つです。この72Bモデルはコーディングや数学などの分野で顕著な能力の改善を持っています。このモデルは29以上の言語をカバーする多言語サポートも提供しており、中国語、英語などが含まれています。モデルは指示の遵守、構造化データの理解、特にJSONのような構造化出力の生成において顕著な向上を示しています。"
  },
  "LoRA/Qwen/Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5-7B-InstructはAlibaba Cloudが発表した最新の大規模言語モデルシリーズの一つです。この7Bモデルはコーディングや数学などの分野で顕著な能力の改善を持っています。このモデルは29以上の言語をカバーする多言語サポートも提供しており、中国語、英語などが含まれています。モデルは指示の遵守、構造化データの理解、特にJSONのような構造化出力の生成において顕著な向上を示しています。"
  },
  "Meta-Llama-3.1-405B-Instruct": {
    "description": "Llama 3.1の指示調整されたテキストモデルで、多言語対話のユースケースに最適化されており、多くの利用可能なオープンソースおよびクローズドチャットモデルの中で、一般的な業界ベンチマークで優れた性能を発揮します。"
  },
  "Meta-Llama-3.1-70B-Instruct": {
    "description": "Llama 3.1の指示調整されたテキストモデルで、多言語対話のユースケースに最適化されており、多くの利用可能なオープンソースおよびクローズドチャットモデルの中で、一般的な業界ベンチマークで優れた性能を発揮します。"
  },
  "Meta-Llama-3.1-8B-Instruct": {
    "description": "Llama 3.1の指示調整されたテキストモデルで、多言語対話のユースケースに最適化されており、多くの利用可能なオープンソースおよびクローズドチャットモデルの中で、一般的な業界ベンチマークで優れた性能を発揮します。"
  },
  "Meta-Llama-3.2-1B-Instruct": {
    "description": "最先端の小型言語モデルで、言語理解、優れた推論能力、テキスト生成能力を備えています。"
  },
  "Meta-Llama-3.2-3B-Instruct": {
    "description": "最先端の小型言語モデルで、言語理解、優れた推論能力、テキスト生成能力を備えています。"
  },
  "Meta-Llama-3.3-70B-Instruct": {
    "description": "Llama 3.3は、Llamaシリーズの最先端の多言語オープンソース大規模言語モデルで、非常に低コストで405Bモデルに匹敵する性能を体験できます。Transformer構造に基づき、監視付き微調整（SFT）と人間のフィードバックによる強化学習（RLHF）を通じて有用性と安全性を向上させています。その指示調整バージョンは多言語対話に最適化されており、さまざまな業界のベンチマークで多くのオープンソースおよびクローズドチャットモデルを上回る性能を発揮します。知識のカットオフ日は2023年12月です。"
  },
  "MiniMax-Text-01": {
    "description": "MiniMax-01シリーズモデルでは、大胆な革新を行いました：初めて大規模に線形注意メカニズムを実現し、従来のTransformerアーキテクチャが唯一の選択肢ではなくなりました。このモデルのパラメータ数は4560億に達し、単回のアクティベーションは459億です。モデルの総合性能は海外のトップモデルに匹敵し、世界最長の400万トークンのコンテキストを効率的に処理でき、GPT-4oの32倍、Claude-3.5-Sonnetの20倍です。"
  },
  "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO": {
    "description": "Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B)は、高精度の指示モデルであり、複雑な計算に適しています。"
  },
  "OpenGVLab/InternVL2-26B": {
    "description": "InternVL2はさまざまな視覚と言語タスクで卓越した性能を発揮しており、文書や図表の理解、シーンテキストの理解、OCR、科学および数学の問題解決などを含みます。"
  },
  "Phi-3-medium-128k-instruct": {
    "description": "同じPhi-3-mediumモデルですが、RAGまたは少数ショットプロンプティング用により大きなコンテキストサイズを持っています。"
  },
  "Phi-3-medium-4k-instruct": {
    "description": "14Bパラメータのモデルで、Phi-3-miniよりも高品質で、質の高い推論密度のデータに焦点を当てています。"
  },
  "Phi-3-mini-128k-instruct": {
    "description": "同じPhi-3-miniモデルですが、RAGまたは少数ショットプロンプティング用により大きなコンテキストサイズを持っています。"
  },
  "Phi-3-mini-4k-instruct": {
    "description": "Phi-3ファミリーの最小メンバー。品質と低遅延の両方に最適化されています。"
  },
  "Phi-3-small-128k-instruct": {
    "description": "同じPhi-3-smallモデルですが、RAGまたは少数ショットプロンプティング用により大きなコンテキストサイズを持っています。"
  },
  "Phi-3-small-8k-instruct": {
    "description": "7Bパラメータのモデルで、Phi-3-miniよりも高品質で、質の高い推論密度のデータに焦点を当てています。"
  },
  "Phi-3.5-mini-instruct": {
    "description": "Phi-3-miniモデルの更新版です。"
  },
  "Phi-3.5-vision-instrust": {
    "description": "Phi-3-visionモデルの更新版です。"
  },
  "Pro/OpenGVLab/InternVL2-8B": {
    "description": "InternVL2はさまざまな視覚と言語タスクで卓越した性能を発揮しており、文書や図表の理解、シーンテキストの理解、OCR、科学および数学の問題解決などを含みます。"
  },
  "Pro/Qwen/Qwen2-1.5B-Instruct": {
    "description": "Qwen2-1.5B-InstructはQwen2シリーズの指示微調整大規模言語モデルで、パラメータ規模は1.5Bです。このモデルはTransformerアーキテクチャに基づき、SwiGLU活性化関数、注意QKVバイアス、グループクエリ注意などの技術を採用しています。言語理解、生成、多言語能力、コーディング、数学、推論などの複数のベンチマークテストで優れたパフォーマンスを示し、ほとんどのオープンソースモデルを超えています。Qwen1.5-1.8B-Chatと比較して、Qwen2-1.5B-InstructはMMLU、HumanEval、GSM8K、C-Eval、IFEvalなどのテストで顕著な性能向上を示していますが、パラメータ数はわずかに少ないです。"
  },
  "Pro/Qwen/Qwen2-7B-Instruct": {
    "description": "Qwen2-7B-InstructはQwen2シリーズの指示微調整大規模言語モデルで、パラメータ規模は7Bです。このモデルはTransformerアーキテクチャに基づき、SwiGLU活性化関数、注意QKVバイアス、グループクエリ注意などの技術を採用しています。大規模な入力を処理することができます。このモデルは言語理解、生成、多言語能力、コーディング、数学、推論などの複数のベンチマークテストで優れたパフォーマンスを示し、ほとんどのオープンソースモデルを超え、特定のタスクでは専有モデルと同等の競争力を示しています。Qwen2-7B-Instructは多くの評価でQwen1.5-7B-Chatを上回り、顕著な性能向上を示しています。"
  },
  "Pro/Qwen/Qwen2-VL-7B-Instruct": {
    "description": "Qwen2-VLはQwen-VLモデルの最新のイテレーションで、視覚理解のベンチマークテストで最先端の性能を達成しました。"
  },
  "Pro/Qwen/Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5-7B-InstructはAlibaba Cloudが発表した最新の大規模言語モデルシリーズの一つです。この7Bモデルはコーディングや数学などの分野で顕著な能力の改善を持っています。このモデルは29以上の言語をカバーする多言語サポートも提供しており、中国語、英語などが含まれています。モデルは指示の遵守、構造化データの理解、特にJSONのような構造化出力の生成において顕著な向上を示しています。"
  },
  "Pro/Qwen/Qwen2.5-Coder-7B-Instruct": {
    "description": "Qwen2.5-Coder-7B-InstructはAlibaba Cloudが発表したコード特化型大規模言語モデルシリーズの最新バージョンです。このモデルはQwen2.5を基に、55兆トークンの訓練を通じて、コード生成、推論、修正能力を大幅に向上させました。コーディング能力を強化するだけでなく、数学および一般的な能力の利点も維持しています。このモデルはコードエージェントなどの実際のアプリケーションに対して、より包括的な基盤を提供します。"
  },
  "Pro/THUDM/glm-4-9b-chat": {
    "description": "GLM-4-9B-Chatは智譜AIが提供するGLM-4シリーズの事前訓練モデルのオープンバージョンです。このモデルは意味、数学、推論、コード、知識などの複数の側面で優れたパフォーマンスを示します。多輪対話をサポートするだけでなく、GLM-4-9B-Chatはウェブブラウジング、コード実行、カスタムツール呼び出し（Function Call）、長文推論などの高度な機能も備えています。モデルは中国語、英語、日本語、韓国語、ドイツ語など26の言語をサポートしています。多くのベンチマークテストで、GLM-4-9B-Chatは優れた性能を示し、AlignBench-v2、MT-Bench、MMLU、C-Evalなどでの評価が行われています。このモデルは最大128Kのコンテキスト長をサポートし、学術研究や商業アプリケーションに適しています。"
  },
  "Pro/deepseek-ai/DeepSeek-R1": {
    "description": "DeepSeek-R1は、強化学習（RL）駆動の推論モデルで、モデル内の繰り返しと可読性の問題を解決します。RLの前に、DeepSeek-R1はコールドスタートデータを導入し、推論性能をさらに最適化しました。数学、コード、推論タスクにおいてOpenAI-o1と同等の性能を発揮し、精巧に設計されたトレーニング手法によって全体的な効果を向上させています。"
  },
  "Pro/deepseek-ai/DeepSeek-V3": {
    "description": "DeepSeek-V3は、6710億パラメータを持つ混合専門家（MoE）言語モデルで、多頭潜在注意力（MLA）とDeepSeekMoEアーキテクチャを採用し、無補助損失の負荷バランス戦略を組み合わせて推論とトレーニングの効率を最適化しています。14.8兆の高品質トークンで事前トレーニングを行い、監視付き微調整と強化学習を経て、DeepSeek-V3は他のオープンソースモデルを超え、先進的なクローズドモデルに近づいています。"
  },
  "Pro/google/gemma-2-9b-it": {
    "description": "GemmaはGoogleが開発した軽量で最先端のオープンモデルシリーズの一つです。これはデコーダーのみの大規模言語モデルで、英語をサポートし、オープンウェイト、事前訓練バリアント、指示微調整バリアントを提供します。Gemmaモデルは質問応答、要約、推論などのさまざまなテキスト生成タスクに適しています。この9Bモデルは8兆トークンで訓練されました。その比較的小さな規模により、リソースが限られた環境（ノートパソコン、デスクトップ、または自分のクラウドインフラストラクチャなど）でのデプロイが可能になり、より多くの人々が最先端のAIモデルにアクセスできるようになり、革新を促進します。"
  },
  "Pro/meta-llama/Meta-Llama-3.1-8B-Instruct": {
    "description": "Meta Llama 3.1はMetaが開発した多言語大規模言語モデルファミリーで、8B、70B、405Bの3つのパラメータ規模の事前訓練および指示微調整バリアントを含みます。この8B指示微調整モデルは多言語対話シーンに最適化されており、複数の業界ベンチマークテストで優れたパフォーマンスを示しています。モデルの訓練には150兆トークン以上の公開データが使用され、監視微調整や人間のフィードバック強化学習などの技術が採用され、モデルの有用性と安全性が向上しています。Llama 3.1はテキスト生成とコード生成をサポートし、知識のカットオフ日は2023年12月です。"
  },
  "QwQ-32B-Preview": {
    "description": "QwQ-32B-Previewは、複雑な対話生成と文脈理解タスクを効率的に処理できる革新的な自然言語処理モデルです。"
  },
  "Qwen/QVQ-72B-Preview": {
    "description": "QVQ-72B-Previewは、Qwenチームによって開発された視覚推論能力に特化した研究モデルであり、複雑なシーン理解と視覚関連の数学問題を解決する上で独自の利点を持っています。"
  },
  "Qwen/QwQ-32B-Preview": {
    "description": "QwQ-32B-PreviewはQwenの最新の実験的研究モデルで、AIの推論能力を向上させることに特化しています。言語の混合、再帰的推論などの複雑なメカニズムを探求することで、主な利点は強力な推論分析能力、数学およびプログラミング能力です。同時に、言語切り替えの問題、推論のループ、安全性の考慮、その他の能力の違いも存在します。"
  },
  "Qwen/Qwen2-1.5B-Instruct": {
    "description": "Qwen2-1.5B-InstructはQwen2シリーズの指示微調整大規模言語モデルで、パラメータ規模は1.5Bです。このモデルはTransformerアーキテクチャに基づき、SwiGLU活性化関数、注意QKVバイアス、グループクエリ注意などの技術を採用しています。言語理解、生成、多言語能力、コーディング、数学、推論などの複数のベンチマークテストで優れたパフォーマンスを示し、ほとんどのオープンソースモデルを超えています。Qwen1.5-1.8B-Chatと比較して、Qwen2-1.5B-InstructはMMLU、HumanEval、GSM8K、C-Eval、IFEvalなどのテストで顕著な性能向上を示していますが、パラメータ数はわずかに少ないです。"
  },
  "Qwen/Qwen2-72B-Instruct": {
    "description": "Qwen2は、先進的な汎用言語モデルであり、さまざまな指示タイプをサポートします。"
  },
  "Qwen/Qwen2-7B-Instruct": {
    "description": "Qwen2-72B-InstructはQwen2シリーズの指示微調整大規模言語モデルで、パラメータ規模は72Bです。このモデルはTransformerアーキテクチャに基づき、SwiGLU活性化関数、注意QKVバイアス、グループクエリ注意などの技術を採用しています。大規模な入力を処理することができます。このモデルは言語理解、生成、多言語能力、コーディング、数学、推論などの複数のベンチマークテストで優れたパフォーマンスを示し、ほとんどのオープンソースモデルを超え、特定のタスクでは専有モデルと同等の競争力を示しています。"
  },
  "Qwen/Qwen2-VL-72B-Instruct": {
    "description": "Qwen2-VLはQwen-VLモデルの最新のイテレーションで、視覚理解のベンチマークテストで最先端の性能を達成しました。"
  },
  "Qwen/Qwen2.5-14B-Instruct": {
    "description": "Qwen2.5は、新しい大型言語モデルシリーズで、指示型タスクの処理を最適化することを目的としています。"
  },
  "Qwen/Qwen2.5-32B-Instruct": {
    "description": "Qwen2.5は、新しい大型言語モデルシリーズで、指示型タスクの処理を最適化することを目的としています。"
  },
  "Qwen/Qwen2.5-72B-Instruct": {
    "description": "アリババクラウドの通義千問チームが開発した大規模言語モデル"
  },
  "Qwen/Qwen2.5-72B-Instruct-128K": {
    "description": "Qwen2.5は新しい大型言語モデルシリーズで、より強力な理解と生成能力を持っています。"
  },
  "Qwen/Qwen2.5-72B-Instruct-Turbo": {
    "description": "Qwen2.5は新しい大型言語モデルシリーズで、指示タスクの処理を最適化することを目的としています。"
  },
  "Qwen/Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5は、新しい大型言語モデルシリーズで、指示型タスクの処理を最適化することを目的としています。"
  },
  "Qwen/Qwen2.5-7B-Instruct-Turbo": {
    "description": "Qwen2.5は新しい大型言語モデルシリーズで、指示タスクの処理を最適化することを目的としています。"
  },
  "Qwen/Qwen2.5-Coder-32B-Instruct": {
    "description": "Qwen2.5-Coderはコード作成に特化しています。"
  },
  "Qwen/Qwen2.5-Coder-7B-Instruct": {
    "description": "Qwen2.5-Coder-7B-InstructはAlibaba Cloudが発表したコード特化型大規模言語モデルシリーズの最新バージョンです。このモデルはQwen2.5を基に、55兆トークンの訓練を通じて、コード生成、推論、修正能力を大幅に向上させました。コーディング能力を強化するだけでなく、数学および一般的な能力の利点も維持しています。このモデルはコードエージェントなどの実際のアプリケーションに対して、より包括的な基盤を提供します。"
  },
  "Qwen2-72B-Instruct": {
    "description": "Qwen2はQwenモデルの最新シリーズで、128kのコンテキストをサポートしています。現在の最適なオープンソースモデルと比較して、Qwen2-72Bは自然言語理解、知識、コード、数学、そして多言語などの能力において、現在のリーディングモデルを大幅に上回っています。"
  },
  "Qwen2-7B-Instruct": {
    "description": "Qwen2はQwenモデルの最新シリーズで、同等の規模の最適なオープンソースモデルやそれ以上の規模のモデルを超えることができ、Qwen2 7Bは複数の評価で顕著な優位性を示し、特にコードと中国語理解において優れています。"
  },
  "Qwen2-VL-72B": {
    "description": "Qwen2-VL-72Bは、強力な視覚言語モデルであり、画像とテキストのマルチモーダル処理をサポートし、画像の内容を正確に認識し、関連する説明や回答を生成できます。"
  },
  "Qwen2.5-14B-Instruct": {
    "description": "Qwen2.5-14B-Instructは、140億パラメータの大規模言語モデルで、優れたパフォーマンスを発揮し、中国語と多言語シーンを最適化し、インテリジェントQ&A、コンテンツ生成などのアプリケーションをサポートします。"
  },
  "Qwen2.5-32B-Instruct": {
    "description": "Qwen2.5-32B-Instructは、320億パラメータの大規模言語モデルで、パフォーマンスが均衡しており、中国語と多言語シーンを最適化し、インテリジェントQ&A、コンテンツ生成などのアプリケーションをサポートします。"
  },
  "Qwen2.5-72B-Instruct": {
    "description": "Qwen2.5-72B-Instructは、16kのコンテキストをサポートし、8Kを超える長文を生成します。関数呼び出しと外部システムとのシームレスなインタラクションをサポートし、柔軟性と拡張性を大幅に向上させました。モデルの知識は明らかに増加し、コーディングと数学の能力が大幅に向上し、29以上の言語をサポートしています。"
  },
  "Qwen2.5-7B-Instruct": {
    "description": "Qwen2.5-7B-Instructは、70億パラメータの大規模言語モデルで、関数呼び出しと外部システムとのシームレスなインタラクションをサポートし、柔軟性と拡張性を大幅に向上させます。中国語と多言語シーンを最適化し、インテリジェントQ&A、コンテンツ生成などのアプリケーションをサポートします。"
  },
  "Qwen2.5-Coder-14B-Instruct": {
    "description": "Qwen2.5-Coder-14B-Instructは、大規模な事前学習に基づくプログラミング指示モデルであり、強力なコード理解と生成能力を持ち、さまざまなプログラミングタスクを効率的に処理でき、特にスマートコード作成、自動化スクリプト生成、プログラミング問題の解決に適しています。"
  },
  "Qwen2.5-Coder-32B-Instruct": {
    "description": "Qwen2.5-Coder-32B-Instructは、コード生成、コード理解、効率的な開発シーンのために設計された大規模言語モデルで、業界をリードする32Bパラメータ規模を採用しており、多様なプログラミングニーズに応えます。"
  },
  "SenseChat": {
    "description": "基本バージョンのモデル (V4)、4Kのコンテキスト長で、汎用能力が強力です。"
  },
  "SenseChat-128K": {
    "description": "基本バージョンのモデル (V4)、128Kのコンテキスト長で、長文理解や生成などのタスクで優れたパフォーマンスを発揮します。"
  },
  "SenseChat-32K": {
    "description": "基本バージョンのモデル (V4)、32Kのコンテキスト長で、さまざまなシーンに柔軟に適用できます。"
  },
  "SenseChat-5": {
    "description": "最新バージョンのモデル (V5.5)、128Kのコンテキスト長で、数学的推論、英語の対話、指示のフォロー、長文理解などの分野での能力が大幅に向上し、GPT-4oに匹敵します。"
  },
  "SenseChat-5-1202": {
    "description": "V5.5に基づく最新バージョンで、前のバージョンに比べて中国語と英語の基本能力、チャット、理系知識、人文系知識、ライティング、数理論理、文字数制御などのいくつかの次元でのパフォーマンスが大幅に向上しています。"
  },
  "SenseChat-5-Cantonese": {
    "description": "32Kのコンテキスト長で、広東語の対話理解においてGPT-4を超え、知識、推論、数学、コード作成などの複数の分野でGPT-4 Turboに匹敵します。"
  },
  "SenseChat-Character": {
    "description": "スタンダード版モデル、8Kのコンテキスト長で、高速な応答速度を持っています。"
  },
  "SenseChat-Character-Pro": {
    "description": "ハイエンド版モデル、32Kのコンテキスト長で、能力が全面的に向上し、中国語/英語の対話をサポートしています。"
  },
  "SenseChat-Turbo": {
    "description": "迅速な質問応答やモデルの微調整シーンに適しています。"
  },
  "SenseChat-Turbo-1202": {
    "description": "最新の軽量バージョンモデルで、フルモデルの90%以上の能力を達成し、推論コストを大幅に削減しています。"
  },
  "SenseChat-Vision": {
    "description": "最新バージョンモデル (V5.5) で、複数の画像入力をサポートし、モデルの基本能力の最適化を全面的に実現し、オブジェクト属性認識、空間関係、動作イベント認識、シーン理解、感情認識、論理常識推論、テキスト理解生成において大幅な向上を実現しました。"
  },
  "Skylark2-lite-8k": {
    "description": "雲雀（Skylark）第2世代モデル、Skylark2-liteモデルは高い応答速度を持ち、リアルタイム性が求められ、コストに敏感で、モデルの精度要求がそれほど高くないシーンに適しています。コンテキストウィンドウ長は8kです。"
  },
  "Skylark2-pro-32k": {
    "description": "雲雀（Skylark）第2世代モデル、Skylark2-proバージョンは高いモデル精度を持ち、専門分野の文書生成、小説創作、高品質翻訳などの複雑なテキスト生成シーンに適しています。コンテキストウィンドウ長は32kです。"
  },
  "Skylark2-pro-4k": {
    "description": "雲雀（Skylark）第2世代モデル、Skylark2-proモデルは高いモデル精度を持ち、専門分野の文書生成、小説創作、高品質翻訳などの複雑なテキスト生成シーンに適しています。コンテキストウィンドウ長は4kです。"
  },
  "Skylark2-pro-character-4k": {
    "description": "雲雀（Skylark）第2世代モデル、Skylark2-pro-characterモデルは、優れたロールプレイングとチャット能力を持ち、ユーザーのプロンプト要件に基づいて異なるキャラクターを演じながらチャットを行うのが得意です。キャラクターのスタイルが際立ち、対話の内容は自然で流暢です。チャットボット、仮想アシスタント、オンラインカスタマーサービスなどのシーンに適しており、高速な応答を実現します。"
  },
  "Skylark2-pro-turbo-8k": {
    "description": "雲雀（Skylark）第2世代モデル、Skylark2-pro-turbo-8kは、推論がより速く、コストが低く、コンテキストウィンドウ長は8kです。"
  },
  "THUDM/chatglm3-6b": {
    "description": "ChatGLM3-6BはChatGLMシリーズのオープンモデルで、智譜AIによって開発されました。このモデルは前の世代の優れた特性を保持し、対話の流暢さとデプロイのハードルの低さを維持しつつ、新しい特性を導入しています。より多様な訓練データ、より十分な訓練ステップ、より合理的な訓練戦略を採用し、10B未満の事前訓練モデルの中で優れたパフォーマンスを示しています。ChatGLM3-6Bは多輪対話、ツール呼び出し、コード実行、エージェントタスクなどの複雑なシーンをサポートしています。対話モデルの他に、基礎モデルChatGLM-6B-Baseと長文対話モデルChatGLM3-6B-32Kもオープンソースとして提供されています。このモデルは学術研究に完全にオープンで、登録後は無料の商業利用も許可されています。"
  },
  "THUDM/glm-4-9b-chat": {
    "description": "GLM-4 9Bはオープンソース版で、会話アプリケーションに最適化された対話体験を提供します。"
  },
  "TeleAI/TeleChat2": {
    "description": "TeleChat2大モデルは中国電信が0から1まで自主開発した生成的意味大モデルで、百科問答、コード生成、長文生成などの機能をサポートし、ユーザーに対話相談サービスを提供します。ユーザーと対話し、質問に答え、創作を支援し、効率的かつ便利に情報、知識、インスピレーションを取得する手助けをします。モデルは幻覚問題、長文生成、論理理解などの面で優れたパフォーマンスを示しています。"
  },
  "TeleAI/TeleMM": {
    "description": "TeleMM多モーダル大モデルは中国電信が自主開発した多モーダル理解大モデルで、テキスト、画像などの多様なモーダル入力を処理し、画像理解、グラフ分析などの機能をサポートし、ユーザーにクロスモーダルの理解サービスを提供します。モデルはユーザーと多モーダルでインタラクションし、入力内容を正確に理解し、質問に答え、創作を支援し、効率的に多モーダル情報とインスピレーションのサポートを提供します。細粒度の認識、論理推論などの多モーダルタスクで優れたパフォーマンスを示しています。"
  },
  "Vendor-A/Qwen/Qwen2.5-72B-Instruct": {
    "description": "Qwen2.5-72B-InstructはAlibaba Cloudが発表した最新の大規模言語モデルシリーズの一つです。この72Bモデルはコーディングや数学などの分野で顕著な能力の改善を持っています。このモデルは29以上の言語をカバーする多言語サポートも提供しており、中国語、英語などが含まれています。モデルは指示の遵守、構造化データの理解、特にJSONのような構造化出力の生成において顕著な向上を示しています。"
  },
  "Yi-34B-Chat": {
    "description": "Yi-1.5-34Bは、元のシリーズモデルの優れた汎用言語能力を維持しつつ、5000億の高品質トークンを増分トレーニングすることで、数学的論理とコーディング能力を大幅に向上させました。"
  },
  "abab5.5-chat": {
    "description": "生産性シーン向けであり、複雑なタスク処理と効率的なテキスト生成をサポートし、専門分野のアプリケーションに適しています。"
  },
  "abab5.5s-chat": {
    "description": "中国語のキャラクター対話シーンに特化しており、高品質な中国語対話生成能力を提供し、さまざまなアプリケーションシーンに適しています。"
  },
  "abab6.5g-chat": {
    "description": "多言語のキャラクター対話に特化しており、英語および他の多くの言語の高品質な対話生成をサポートします。"
  },
  "abab6.5s-chat": {
    "description": "テキスト生成、対話システムなど、幅広い自然言語処理タスクに適しています。"
  },
  "abab6.5t-chat": {
    "description": "中国語のキャラクター対話シーンに最適化されており、流暢で中国語の表現習慣に合った対話生成能力を提供します。"
  },
  "accounts/fireworks/models/deepseek-r1": {
    "description": "DeepSeek-R1は、強化学習とコールドスタートデータの最適化を経た最先端の大規模言語モデルで、優れた推論、数学、プログラミング性能を持っています。"
  },
  "accounts/fireworks/models/deepseek-v3": {
    "description": "Deepseekが提供する強力なMixture-of-Experts (MoE)言語モデルで、総パラメータ数は671Bであり、各トークンは37Bのパラメータを活性化します。"
  },
  "accounts/fireworks/models/llama-v3-70b-instruct": {
    "description": "Llama 3 70B指示モデルは、多言語対話と自然言語理解に最適化されており、ほとんどの競合モデルを上回る性能を持っています。"
  },
  "accounts/fireworks/models/llama-v3-8b-instruct": {
    "description": "Llama 3 8B指示モデルは、対話や多言語タスクに最適化されており、卓越した効率を発揮します。"
  },
  "accounts/fireworks/models/llama-v3-8b-instruct-hf": {
    "description": "Llama 3 8B指示モデル（HFバージョン）は、公式実装結果と一致し、高い一貫性とクロスプラットフォーム互換性を持っています。"
  },
  "accounts/fireworks/models/llama-v3p1-405b-instruct": {
    "description": "Llama 3.1 405B指示モデルは、超大規模なパラメータを持ち、複雑なタスクや高負荷シナリオでの指示フォローに適しています。"
  },
  "accounts/fireworks/models/llama-v3p1-70b-instruct": {
    "description": "Llama 3.1 70B指示モデルは、卓越した自然言語理解と生成能力を提供し、対話や分析タスクに理想的な選択肢です。"
  },
  "accounts/fireworks/models/llama-v3p1-8b-instruct": {
    "description": "Llama 3.1 8B指示モデルは、多言語対話の最適化のために設計されており、一般的な業界ベンチマークを超える性能を発揮します。"
  },
  "accounts/fireworks/models/llama-v3p2-11b-vision-instruct": {
    "description": "Metaの11Bパラメータ指示調整画像推論モデルです。このモデルは視覚認識、画像推論、画像説明、および画像に関する一般的な質問への回答に最適化されています。このモデルは、グラフや図表などの視覚データを理解し、画像の詳細をテキストで記述することで、視覚と言語の間のギャップを埋めることができます。"
  },
  "accounts/fireworks/models/llama-v3p2-3b-instruct": {
    "description": "Llama 3.2 3B指示モデルはMetaが発表した軽量な多言語モデルです。このモデルは効率を向上させることを目的としており、より大規模なモデルと比較して遅延とコストの面で大きな改善を提供します。このモデルの使用例には、問い合わせやプロンプトのリライト、執筆支援が含まれます。"
  },
  "accounts/fireworks/models/llama-v3p2-90b-vision-instruct": {
    "description": "Metaの90Bパラメータ指示調整画像推論モデルです。このモデルは視覚認識、画像推論、画像説明、および画像に関する一般的な質問への回答に最適化されています。このモデルは、グラフや図表などの視覚データを理解し、画像の詳細をテキストで記述することで、視覚と言語の間のギャップを埋めることができます。"
  },
  "accounts/fireworks/models/llama-v3p3-70b-instruct": {
    "description": "Llama 3.3 70B Instructは、Llama 3.1 70Bの12月の更新版です。このモデルは、2024年7月にリリースされたLlama 3.1 70Bを基に改良され、ツール呼び出し、多言語テキストサポート、数学およびプログラミング能力が強化されています。このモデルは、推論、数学、指示遵守の面で業界の最前線に達しており、3.1 405Bと同等の性能を提供しつつ、速度とコストにおいて顕著な利点を持っています。"
  },
  "accounts/fireworks/models/mistral-small-24b-instruct-2501": {
    "description": "24Bパラメータモデルで、より大規模なモデルと同等の最先端の能力を備えています。"
  },
  "accounts/fireworks/models/mixtral-8x22b-instruct": {
    "description": "Mixtral MoE 8x22B指示モデルは、大規模なパラメータと多専門家アーキテクチャを持ち、複雑なタスクの高効率処理を全方位でサポートします。"
  },
  "accounts/fireworks/models/mixtral-8x7b-instruct": {
    "description": "Mixtral MoE 8x7B指示モデルは、多専門家アーキテクチャを提供し、高効率の指示フォローと実行をサポートします。"
  },
  "accounts/fireworks/models/mythomax-l2-13b": {
    "description": "MythoMax L2 13Bモデルは、新しい統合技術を組み合わせており、物語やキャラクターの役割に優れています。"
  },
  "accounts/fireworks/models/phi-3-vision-128k-instruct": {
    "description": "Phi 3 Vision指示モデルは、軽量の多モーダルモデルであり、複雑な視覚とテキスト情報を処理でき、強力な推論能力を持っています。"
  },
  "accounts/fireworks/models/qwen-qwq-32b-preview": {
    "description": "QwQモデルはQwenチームによって開発された実験的な研究モデルで、AIの推論能力を強化することに焦点を当てています。"
  },
  "accounts/fireworks/models/qwen2-vl-72b-instruct": {
    "description": "Qwen-VLモデルの72Bバージョンは、アリババの最新のイテレーションの成果であり、近年の革新を代表しています。"
  },
  "accounts/fireworks/models/qwen2p5-72b-instruct": {
    "description": "Qwen2.5はAlibaba Cloud Qwenチームによって開発された一連のデコーダーのみを含む言語モデルです。これらのモデルは、0.5B、1.5B、3B、7B、14B、32B、72Bなど、さまざまなサイズを提供し、ベース版と指示版の2種類のバリエーションがあります。"
  },
  "accounts/fireworks/models/qwen2p5-coder-32b-instruct": {
    "description": "Qwen2.5 Coder 32B InstructはAlibaba Cloudが発表したコード特化型大規模言語モデルシリーズの最新バージョンです。このモデルはQwen2.5を基に、55兆トークンの訓練を通じて、コード生成、推論、修正能力を大幅に向上させました。コーディング能力を強化するだけでなく、数学および一般的な能力の利点も維持しています。このモデルはコードエージェントなどの実際のアプリケーションに対して、より包括的な基盤を提供します。"
  },
  "accounts/yi-01-ai/models/yi-large": {
    "description": "Yi-Largeモデルは、卓越した多言語処理能力を持ち、さまざまな言語生成と理解タスクに使用できます。"
  },
  "ai21-jamba-1.5-large": {
    "description": "398Bパラメータ（94Bアクティブ）の多言語モデルで、256Kの長いコンテキストウィンドウ、関数呼び出し、構造化出力、基盤生成を提供します。"
  },
  "ai21-jamba-1.5-mini": {
    "description": "52Bパラメータ（12Bアクティブ）の多言語モデルで、256Kの長いコンテキストウィンドウ、関数呼び出し、構造化出力、基盤生成を提供します。"
  },
  "anthropic.claude-3-5-sonnet-20240620-v1:0": {
    "description": "Claude 3.5 Sonnetは業界標準を向上させ、競合モデルやClaude 3 Opusを超える性能を持ち、広範な評価で優れたパフォーマンスを示し、私たちの中程度のモデルの速度とコストを兼ね備えています。"
  },
  "anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "description": "Claude 3.5 Sonnetは業界標準を引き上げ、競合モデルやClaude 3 Opusを上回る性能を発揮し、広範な評価で優れた結果を示しています。また、中程度のレベルのモデルと同等の速度とコストを持っています。"
  },
  "anthropic.claude-3-7-sonnet-20250219-v1:0": {
    "description": "Claude 3.7 Sonnetは、競合他社よりも低価格で最大の効用を提供し、信頼性が高く耐久性のある主力機として設計されています。スケール化されたAIデプロイメントに適しています。Claude 3.7 Sonnetは画像を処理し、テキスト出力を返すことができ、200Kのコンテキストウィンドウを持っています。"
  },
  "anthropic.claude-3-haiku-20240307-v1:0": {
    "description": "Claude 3 HaikuはAnthropicの最も速く、最もコンパクトなモデルで、ほぼ瞬時の応答速度を提供します。簡単なクエリやリクエストに迅速に回答できます。顧客は人間のインタラクションを模倣するシームレスなAI体験を構築できるようになります。Claude 3 Haikuは画像を処理し、テキスト出力を返すことができ、200Kのコンテキストウィンドウを持っています。"
  },
  "anthropic.claude-3-opus-20240229-v1:0": {
    "description": "Claude 3 OpusはAnthropicの最も強力なAIモデルで、高度に複雑なタスクにおいて最先端の性能を持っています。オープンエンドのプロンプトや未見のシナリオを処理でき、優れた流暢さと人間の理解能力を持っています。Claude 3 Opusは生成AIの可能性の最前線を示しています。Claude 3 Opusは画像を処理し、テキスト出力を返すことができ、200Kのコンテキストウィンドウを持っています。"
  },
  "anthropic.claude-3-sonnet-20240229-v1:0": {
    "description": "AnthropicのClaude 3 Sonnetは、知能と速度の理想的なバランスを実現しており、特に企業のワークロードに適しています。競合他社よりも低価格で最大の効用を提供し、信頼性が高く耐久性のある主力機として設計されており、スケール化されたAIデプロイメントに適しています。Claude 3 Sonnetは画像を処理し、テキスト出力を返すことができ、200Kのコンテキストウィンドウを持っています。"
  },
  "anthropic.claude-instant-v1": {
    "description": "日常の対話、テキスト分析、要約、文書質問応答などの一連のタスクを処理できる、迅速で経済的かつ非常に能力のあるモデルです。"
  },
  "anthropic.claude-v2": {
    "description": "Anthropicは、複雑な対話や創造的なコンテンツ生成から詳細な指示の遵守に至るまで、幅広いタスクで高い能力を発揮するモデルです。"
  },
  "anthropic.claude-v2:1": {
    "description": "Claude 2の更新版で、コンテキストウィンドウが2倍になり、長文書やRAGコンテキストにおける信頼性、幻覚率、証拠に基づく正確性が改善されています。"
  },
  "anthropic/claude-3-haiku": {
    "description": "Claude 3 HaikuはAnthropicの最も迅速でコンパクトなモデルで、ほぼ瞬時の応答を実現することを目的としています。迅速かつ正確な指向性能を備えています。"
  },
  "anthropic/claude-3-opus": {
    "description": "Claude 3 Opusは、Anthropicが高度に複雑なタスクを処理するために開発した最も強力なモデルです。性能、知能、流暢さ、理解力において卓越したパフォーマンスを発揮します。"
  },
  "anthropic/claude-3.5-haiku": {
    "description": "Claude 3.5 Haikuは、Anthropicの最も高速な次世代モデルです。Claude 3 Haikuと比較して、Claude 3.5 Haikuはすべてのスキルで向上しており、多くの知能ベンチマークテストで前世代の最大モデルClaude 3 Opusを超えています。"
  },
  "anthropic/claude-3.5-sonnet": {
    "description": "Claude 3.5 SonnetはOpusを超える能力を提供し、Sonnetよりも速い速度を持ちながら、Sonnetと同じ価格を維持します。Sonnetは特にプログラミング、データサイエンス、視覚処理、代理タスクに優れています。"
  },
  "aya": {
    "description": "Aya 23は、Cohereが提供する多言語モデルであり、23の言語をサポートし、多様な言語アプリケーションを便利にします。"
  },
  "aya:35b": {
    "description": "Aya 23は、Cohereが提供する多言語モデルであり、23の言語をサポートし、多様な言語アプリケーションを便利にします。"
  },
  "charglm-3": {
    "description": "CharGLM-3はキャラクター演技と感情的な伴侶のために設計されており、超長期の多段階記憶と個別化された対話をサポートし、幅広い用途に適しています。"
  },
  "chatgpt-4o-latest": {
    "description": "ChatGPT-4oは、リアルタイムで更新される動的モデルで、常に最新のバージョンを維持します。強力な言語理解と生成能力を組み合わせており、顧客サービス、教育、技術サポートなどの大規模なアプリケーションシナリオに適しています。"
  },
  "claude-2.0": {
    "description": "Claude 2は、業界をリードする200Kトークンのコンテキスト、モデルの幻覚の発生率を大幅に低下させる、システムプロンプト、および新しいテスト機能：ツール呼び出しを含む、企業にとって重要な能力の進歩を提供します。"
  },
  "claude-2.1": {
    "description": "Claude 2は、業界をリードする200Kトークンのコンテキスト、モデルの幻覚の発生率を大幅に低下させる、システムプロンプト、および新しいテスト機能：ツール呼び出しを含む、企業にとって重要な能力の進歩を提供します。"
  },
  "claude-3-5-haiku-20241022": {
    "description": "Claude 3.5 Haikuは、Anthropicの最も高速な次世代モデルです。Claude 3 Haikuと比較して、Claude 3.5 Haikuはすべてのスキルで向上しており、多くの知能ベンチマークテストで前の世代の最大モデルであるClaude 3 Opusを超えています。"
  },
  "claude-3-5-sonnet-20240620": {
    "description": "Claude 3.5 Sonnetは、Opusを超える能力とSonnetよりも速い速度を提供し、Sonnetと同じ価格を維持します。Sonnetは特にプログラミング、データサイエンス、視覚処理、エージェントタスクに優れています。"
  },
  "claude-3-5-sonnet-20241022": {
    "description": "Claude 3.5 Sonnetは、Opusを超える能力とSonnetよりも速い速度を提供しつつ、Sonnetと同じ価格を維持します。Sonnetは特にプログラミング、データサイエンス、視覚処理、代理タスクに優れています。"
  },
  "claude-3-7-sonnet-20250219": {
    "description": "Claude 3.7 Sonnetは、競合他社よりも低価格で最大の効用を提供し、信頼性が高く耐久性のある主力機として設計されています。スケール化されたAIデプロイメントに適しています。Claude 3.7 Sonnetは画像を処理し、テキスト出力を返すことができ、200Kのコンテキストウィンドウを持っています。"
  },
  "claude-3-haiku-20240307": {
    "description": "Claude 3 Haikuは、Anthropicの最も速く、最もコンパクトなモデルであり、ほぼ瞬時の応答を実現することを目的としています。迅速かつ正確な指向性能を持っています。"
  },
  "claude-3-opus-20240229": {
    "description": "Claude 3 Opusは、Anthropicが高度に複雑なタスクを処理するために開発した最も強力なモデルです。性能、知性、流暢さ、理解力において卓越したパフォーマンスを発揮します。"
  },
  "claude-3-sonnet-20240229": {
    "description": "Claude 3 Sonnetは、企業のワークロードに理想的なバランスを提供し、より低価格で最大の効用を提供し、信頼性が高く、大規模な展開に適しています。"
  },
  "codegeex-4": {
    "description": "CodeGeeX-4は強力なAIプログラミングアシスタントで、さまざまなプログラミング言語のインテリジェントな質問応答とコード補完をサポートし、開発効率を向上させます。"
  },
  "codegeex4-all-9b": {
    "description": "CodeGeeX4-ALL-9Bは、多言語コード生成モデルで、コード補完と生成、コードインタープリター、ウェブ検索、関数呼び出し、リポジトリレベルのコードQ&Aを含む包括的な機能をサポートし、ソフトウェア開発のさまざまなシーンをカバーしています。パラメータが10B未満のトップクラスのコード生成モデルです。"
  },
  "codegemma": {
    "description": "CodeGemmaは、さまざまなプログラミングタスクに特化した軽量言語モデルであり、迅速な反復と統合をサポートします。"
  },
  "codegemma:2b": {
    "description": "CodeGemmaは、さまざまなプログラミングタスクに特化した軽量言語モデルであり、迅速な反復と統合をサポートします。"
  },
  "codellama": {
    "description": "Code Llamaは、コード生成と議論に特化したLLMであり、広範なプログラミング言語のサポートを組み合わせて、開発者環境に適しています。"
  },
  "codellama/CodeLlama-34b-Instruct-hf": {
    "description": "Code Llamaはコード生成と議論に特化したLLMで、幅広いプログラミング言語のサポートを組み合わせて、開発者環境に適しています。"
  },
  "codellama:13b": {
    "description": "Code Llamaは、コード生成と議論に特化したLLMであり、広範なプログラミング言語のサポートを組み合わせて、開発者環境に適しています。"
  },
  "codellama:34b": {
    "description": "Code Llamaは、コード生成と議論に特化したLLMであり、広範なプログラミング言語のサポートを組み合わせて、開発者環境に適しています。"
  },
  "codellama:70b": {
    "description": "Code Llamaは、コード生成と議論に特化したLLMであり、広範なプログラミング言語のサポートを組み合わせて、開発者環境に適しています。"
  },
  "codeqwen": {
    "description": "CodeQwen1.5は、大量のコードデータでトレーニングされた大規模言語モデルであり、複雑なプログラミングタスクを解決するために特化しています。"
  },
  "codestral": {
    "description": "Codestralは、Mistral AIの初のコードモデルであり、コード生成タスクに優れたサポートを提供します。"
  },
  "codestral-latest": {
    "description": "Codestralは、コード生成に特化した最先端の生成モデルであり、中間埋め込みやコード補完タスクを最適化しています。"
  },
  "cognitivecomputations/dolphin-mixtral-8x22b": {
    "description": "Dolphin Mixtral 8x22Bは指示遵守、対話、プログラミングのために設計されたモデルです。"
  },
  "cohere-command-r": {
    "description": "Command Rは、RAGとツール使用をターゲットにしたスケーラブルな生成モデルで、企業向けの生産規模のAIを実現します。"
  },
  "cohere-command-r-plus": {
    "description": "Command R+は、企業グレードのワークロードに対応するために設計された最先端のRAG最適化モデルです。"
  },
  "command-r": {
    "description": "Command Rは、対話と長いコンテキストタスクに最適化されたLLMであり、特に動的なインタラクションと知識管理に適しています。"
  },
  "command-r-plus": {
    "description": "Command R+は、リアルな企業シーンと複雑なアプリケーションのために設計された高性能な大規模言語モデルです。"
  },
  "dall-e-2": {
    "description": "第二世代DALL·Eモデル、よりリアルで正確な画像生成をサポートし、解像度は第一世代の4倍です"
  },
  "dall-e-3": {
    "description": "最新のDALL·Eモデル、2023年11月にリリース。よりリアルで正確な画像生成をサポートし、詳細表現力が向上しています"
  },
  "databricks/dbrx-instruct": {
    "description": "DBRX Instructは、高い信頼性の指示処理能力を提供し、多業界アプリケーションをサポートします。"
  },
  "deepseek-ai/DeepSeek-R1": {
    "description": "DeepSeek-R1は、強化学習（RL）駆動の推論モデルであり、モデル内の繰り返しと可読性の問題を解決します。RLの前に、DeepSeek-R1はコールドスタートデータを導入し、推論性能をさらに最適化しました。数学、コード、推論タスクにおいてOpenAI-o1と同等のパフォーマンスを発揮し、精巧に設計されたトレーニング手法によって全体的な効果を向上させました。"
  },
  "deepseek-ai/DeepSeek-R1-Distill-Llama-70B": {
    "description": "DeepSeek-R1蒸留モデルで、強化学習とコールドスタートデータを通じて推論性能を最適化し、オープンソースモデルがマルチタスクの基準を刷新しました。"
  },
  "deepseek-ai/DeepSeek-R1-Distill-Llama-8B": {
    "description": "DeepSeek-R1-Distill-Llama-8Bは、Llama-3.1-8Bに基づいて開発された蒸留モデルです。このモデルは、DeepSeek-R1が生成したサンプルを使用して微調整され、優れた推論能力を示しています。複数のベンチマークテストで良好なパフォーマンスを示し、特にMATH-500では89.1%の正確性を達成し、AIME 2024では50.4%の合格率を達成し、CodeForcesでは1205のスコアを獲得し、8B規模のモデルとして強力な数学とプログラミング能力を示しています。"
  },
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B": {
    "description": "DeepSeek-R1蒸留モデルで、強化学習とコールドスタートデータを通じて推論性能を最適化し、オープンソースモデルがマルチタスクの基準を刷新しました。"
  },
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-14B": {
    "description": "DeepSeek-R1蒸留モデルで、強化学習とコールドスタートデータを通じて推論性能を最適化し、オープンソースモデルがマルチタスクの基準を刷新しました。"
  },
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B": {
    "description": "DeepSeek-R1-Distill-Qwen-32Bは、Qwen2.5-32Bに基づいて知識蒸留によって得られたモデルです。このモデルは、DeepSeek-R1が生成した80万の選りすぐりのサンプルを使用して微調整され、数学、プログラミング、推論などの複数の分野で卓越した性能を示しています。AIME 2024、MATH-500、GPQA Diamondなどの複数のベンチマークテストで優れた成績を収めており、特にMATH-500では94.3%の正確性を達成し、強力な数学的推論能力を示しています。"
  },
  "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B": {
    "description": "DeepSeek-R1-Distill-Qwen-7Bは、Qwen2.5-Math-7Bに基づいて知識蒸留によって得られたモデルです。このモデルは、DeepSeek-R1が生成した80万の選りすぐりのサンプルを使用して微調整され、優れた推論能力を示しています。複数のベンチマークテストで優れた成績を収めており、特にMATH-500では92.8%の正確性を達成し、AIME 2024では55.5%の合格率を達成し、CodeForcesでは1189のスコアを獲得し、7B規模のモデルとして強力な数学とプログラミング能力を示しています。"
  },
  "deepseek-ai/DeepSeek-V2.5": {
    "description": "DeepSeek V2.5は以前のバージョンの優れた特徴を集約し、汎用性とコーディング能力を強化しました。"
  },
  "deepseek-ai/DeepSeek-V3": {
    "description": "DeepSeek-V3は、6710億パラメータを持つ混合専門家（MoE）言語モデルであり、多頭潜在注意（MLA）とDeepSeekMoEアーキテクチャを採用し、補助損失なしの負荷バランス戦略を組み合わせて、推論とトレーニングの効率を最適化します。14.8兆の高品質トークンで事前トレーニングを行い、監視微調整と強化学習を経て、DeepSeek-V3は他のオープンソースモデルを超え、先進的なクローズドソースモデルに近づきました。"
  },
  "deepseek-ai/deepseek-llm-67b-chat": {
    "description": "DeepSeek 67Bは、高い複雑性の対話のために訓練された先進的なモデルです。"
  },
  "deepseek-ai/deepseek-r1": {
    "description": "最先端の効率的なLLMで、推論、数学、プログラミングに優れています。"
  },
  "deepseek-ai/deepseek-vl2": {
    "description": "DeepSeek-VL2は、DeepSeekMoE-27Bに基づいて開発された混合専門家（MoE）視覚言語モデルであり、スパースアクティベーションのMoEアーキテクチャを採用し、わずか4.5Bパラメータを活性化することで卓越した性能を実現しています。このモデルは、視覚的質問応答、光学文字認識、文書/表/グラフ理解、視覚的定位などの複数のタスクで優れたパフォーマンスを発揮します。"
  },
  "deepseek-chat": {
    "description": "一般的な対話能力と強力なコード処理能力を兼ね備えた新しいオープンソースモデルであり、元のChatモデルの対話能力とCoderモデルのコード処理能力を保持しつつ、人間の好みにより良く整合しています。さらに、DeepSeek-V2.5は、執筆タスクや指示に従う能力など、さまざまな面で大幅な向上を実現しました。"
  },
  "deepseek-coder-33B-instruct": {
    "description": "DeepSeek Coder 33Bは、2兆のデータを基にトレーニングされたコード言語モデルで、そのうち87%がコード、13%が中英語です。モデルは16Kのウィンドウサイズと穴埋めタスクを導入し、プロジェクトレベルのコード補完とスニペット埋め機能を提供します。"
  },
  "deepseek-coder-v2": {
    "description": "DeepSeek Coder V2は、オープンソースの混合エキスパートコードモデルであり、コードタスクにおいて優れた性能を発揮し、GPT4-Turboに匹敵します。"
  },
  "deepseek-coder-v2:236b": {
    "description": "DeepSeek Coder V2は、オープンソースの混合エキスパートコードモデルであり、コードタスクにおいて優れた性能を発揮し、GPT4-Turboに匹敵します。"
  },
  "deepseek-r1": {
    "description": "DeepSeek-R1は、強化学習（RL）駆動の推論モデルであり、モデル内の繰り返しと可読性の問題を解決します。RLの前に、DeepSeek-R1はコールドスタートデータを導入し、推論性能をさらに最適化しました。数学、コード、推論タスクにおいてOpenAI-o1と同等のパフォーマンスを発揮し、精巧に設計されたトレーニング手法によって全体的な効果を向上させました。"
  },
  "deepseek-r1-distill-llama-70b": {
    "description": "DeepSeek R1——DeepSeekスイートの中でより大きく、より賢いモデル——がLlama 70Bアーキテクチャに蒸留されました。ベンチマークテストと人間評価に基づき、このモデルは元のLlama 70Bよりも賢く、特に数学と事実の正確性が求められるタスクで優れたパフォーマンスを示します。"
  },
  "deepseek-r1-distill-llama-8b": {
    "description": "DeepSeek-R1-Distillシリーズモデルは、知識蒸留技術を通じて、DeepSeek-R1が生成したサンプルをQwen、Llamaなどのオープンソースモデルに微調整して得られたものです。"
  },
  "deepseek-r1-distill-qwen-1.5b": {
    "description": "DeepSeek-R1-Distillシリーズモデルは、知識蒸留技術を通じて、DeepSeek-R1が生成したサンプルをQwen、Llamaなどのオープンソースモデルに微調整して得られたものです。"
  },
  "deepseek-r1-distill-qwen-14b": {
    "description": "DeepSeek-R1-Distillシリーズモデルは、知識蒸留技術を通じて、DeepSeek-R1が生成したサンプルをQwen、Llamaなどのオープンソースモデルに微調整して得られたものです。"
  },
  "deepseek-r1-distill-qwen-32b": {
    "description": "DeepSeek-R1-Distillシリーズモデルは、知識蒸留技術を通じて、DeepSeek-R1が生成したサンプルをQwen、Llamaなどのオープンソースモデルに微調整して得られたものです。"
  },
  "deepseek-r1-distill-qwen-7b": {
    "description": "DeepSeek-R1-Distillシリーズモデルは、知識蒸留技術を通じて、DeepSeek-R1が生成したサンプルをQwen、Llamaなどのオープンソースモデルに微調整して得られたものです。"
  },
  "deepseek-reasoner": {
    "description": "DeepSeekが提供する推論モデルです。最終的な回答を出力する前に、モデルは思考の連鎖を出力し、最終的な答えの正確性を高めます。"
  },
  "deepseek-v2": {
    "description": "DeepSeek V2は、高効率なMixture-of-Experts言語モデルであり、経済的な処理ニーズに適しています。"
  },
  "deepseek-v2:236b": {
    "description": "DeepSeek V2 236Bは、DeepSeekの設計コードモデルであり、強力なコード生成能力を提供します。"
  },
  "deepseek-v3": {
    "description": "DeepSeek-V3は、杭州深度求索人工知能基礎技術研究有限公司が独自に開発したMoEモデルで、複数の評価で優れた成績を収め、主流のランキングでオープンソースモデルの首位に立っています。V3はV2.5モデルに比べて生成速度が3倍向上し、ユーザーにより迅速でスムーズな使用体験を提供します。"
  },
  "deepseek/deepseek-chat": {
    "description": "汎用性とコード能力を融合させた新しいオープンソースモデルで、元のChatモデルの汎用対話能力とCoderモデルの強力なコード処理能力を保持しつつ、人間の好みにより良く整合しています。さらに、DeepSeek-V2.5は執筆タスク、指示の遵守などの多くの面で大幅な向上を実現しました。"
  },
  "deepseek/deepseek-r1": {
    "description": "DeepSeek-R1は、わずかなラベル付きデータしかない状況で、モデルの推論能力を大幅に向上させました。最終的な回答を出力する前に、モデルは思考の連鎖を出力し、最終的な答えの正確性を向上させます。"
  },
  "deepseek/deepseek-r1:free": {
    "description": "DeepSeek-R1は、わずかなラベル付きデータしかない状況で、モデルの推論能力を大幅に向上させました。最終的な回答を出力する前に、モデルは思考の連鎖を出力し、最終的な答えの正確性を向上させます。"
  },
  "doubao-1.5-lite-32k": {
    "description": "Doubao-1.5-liteは全く新しい世代の軽量版モデルで、極限の応答速度を実現し、効果と遅延の両方で世界トップレベルに達しています。"
  },
  "doubao-1.5-pro-256k": {
    "description": "Doubao-1.5-pro-256kはDoubao-1.5-Proの全面的なアップグレード版で、全体的な効果が10%大幅に向上しました。256kのコンテキストウィンドウでの推論をサポートし、出力長は最大12kトークンをサポートします。より高い性能、より大きなウィンドウ、超高コストパフォーマンスで、より広範なアプリケーションシーンに適しています。"
  },
  "doubao-1.5-pro-32k": {
    "description": "Doubao-1.5-proは全く新しい世代の主力モデルで、性能が全面的にアップグレードされ、知識、コード、推論などの面で卓越したパフォーマンスを発揮します。"
  },
  "emohaa": {
    "description": "Emohaaは心理モデルで、専門的な相談能力を持ち、ユーザーが感情問題を理解するのを助けます。"
  },
  "ernie-3.5-128k": {
    "description": "百度が独自に開発したフラッグシップの大規模言語モデルで、膨大な中英文コーパスをカバーし、強力な汎用能力を持ち、ほとんどの対話質問応答、創作生成、プラグインアプリケーションシーンの要求を満たすことができます。百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。"
  },
  "ernie-3.5-8k": {
    "description": "百度が独自に開発したフラッグシップの大規模言語モデルで、膨大な中英文コーパスをカバーし、強力な汎用能力を持ち、ほとんどの対話質問応答、創作生成、プラグインアプリケーションシーンの要求を満たすことができます。百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。"
  },
  "ernie-3.5-8k-preview": {
    "description": "百度が独自に開発したフラッグシップの大規模言語モデルで、膨大な中英文コーパスをカバーし、強力な汎用能力を持ち、ほとんどの対話質問応答、創作生成、プラグインアプリケーションシーンの要求を満たすことができます。百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。"
  },
  "ernie-4.0-8k-latest": {
    "description": "百度が独自に開発したフラッグシップの超大規模言語モデルで、ERNIE 3.5に比べてモデル能力が全面的にアップグレードされ、さまざまな分野の複雑なタスクシーンに広く適用されます。百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。"
  },
  "ernie-4.0-8k-preview": {
    "description": "百度が独自に開発したフラッグシップの超大規模言語モデルで、ERNIE 3.5に比べてモデル能力が全面的にアップグレードされ、さまざまな分野の複雑なタスクシーンに広く適用されます。百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。"
  },
  "ernie-4.0-turbo-128k": {
    "description": "百度が独自に開発したフラッグシップの超大規模言語モデルで、総合的なパフォーマンスが優れており、さまざまな分野の複雑なタスクシーンに広く適用されます。百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。ERNIE 4.0に比べてパフォーマンスがさらに優れています。"
  },
  "ernie-4.0-turbo-8k-latest": {
    "description": "百度が独自に開発したフラッグシップの超大規模言語モデルで、総合的なパフォーマンスが優れており、さまざまな分野の複雑なタスクシーンに広く適用されます。百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。ERNIE 4.0に比べてパフォーマンスがさらに優れています。"
  },
  "ernie-4.0-turbo-8k-preview": {
    "description": "百度が独自に開発したフラッグシップの超大規模言語モデルで、総合的なパフォーマンスが優れており、さまざまな分野の複雑なタスクシーンに広く適用されます。百度検索プラグインとの自動接続をサポートし、質問応答情報のタイムリーさを保証します。ERNIE 4.0に比べてパフォーマンスがさらに優れています。"
  },
  "ernie-char-8k": {
    "description": "百度が独自に開発した垂直シーン向けの大規模言語モデルで、ゲームのNPC、カスタマーサービスの対話、対話キャラクターの役割演技などのアプリケーションシーンに適しており、キャラクターのスタイルがより鮮明で一貫しており、指示に従う能力が強く、推論性能が優れています。"
  },
  "ernie-char-fiction-8k": {
    "description": "百度が独自に開発した垂直シーン向けの大規模言語モデルで、ゲームのNPC、カスタマーサービスの対話、対話キャラクターの役割演技などのアプリケーションシーンに適しており、キャラクターのスタイルがより鮮明で一貫しており、指示に従う能力が強く、推論性能が優れています。"
  },
  "ernie-lite-8k": {
    "description": "ERNIE Liteは、百度が独自に開発した軽量級の大規模言語モデルで、優れたモデル効果と推論性能を兼ね備え、低計算能力のAIアクセラレータカードでの推論使用に適しています。"
  },
  "ernie-lite-pro-128k": {
    "description": "百度が独自に開発した軽量級の大規模言語モデルで、優れたモデル効果と推論性能を兼ね備え、ERNIE Liteよりも優れた効果を持ち、低計算能力のAIアクセラレータカードでの推論使用に適しています。"
  },
  "ernie-novel-8k": {
    "description": "百度が独自に開発した汎用大規模言語モデルで、小説の続編作成能力に明らかな優位性があり、短編劇や映画などのシーンにも使用できます。"
  },
  "ernie-speed-128k": {
    "description": "百度が2024年に最新リリースした自社開発の高性能大規模言語モデルで、汎用能力が優れており、基盤モデルとして微調整に適しており、特定のシーンの問題をより良く処理し、優れた推論性能を持っています。"
  },
  "ernie-speed-pro-128k": {
    "description": "百度が2024年に最新リリースした自社開発の高性能大規模言語モデルで、汎用能力が優れており、ERNIE Speedよりも優れた効果を持ち、基盤モデルとして微調整に適しており、特定のシーンの問題をより良く処理し、優れた推論性能を持っています。"
  },
  "ernie-tiny-8k": {
    "description": "ERNIE Tinyは、百度が独自に開発した超高性能の大規模言語モデルで、文心シリーズモデルの中でデプロイと微調整コストが最も低いです。"
  },
  "gemini-1.0-pro-001": {
    "description": "Gemini 1.0 Pro 001（チューニング）は、安定した調整可能な性能を提供し、複雑なタスクのソリューションに理想的な選択肢です。"
  },
  "gemini-1.0-pro-002": {
    "description": "Gemini 1.0 Pro 002（チューニング）は、優れたマルチモーダルサポートを提供し、複雑なタスクの効果的な解決に焦点を当てています。"
  },
  "gemini-1.0-pro-latest": {
    "description": "Gemini 1.0 Proは、Googleの高性能AIモデルであり、幅広いタスクの拡張に特化しています。"
  },
  "gemini-1.5-flash": {
    "description": "Gemini 1.5 Flashは、Googleの最新のマルチモーダルAIモデルで、高速処理能力を備え、テキスト、画像、動画の入力をサポートし、さまざまなタスクに対して効率的に拡張できます。"
  },
  "gemini-1.5-flash-001": {
    "description": "Gemini 1.5 Flash 001は、効率的なマルチモーダルモデルであり、幅広いアプリケーションの拡張をサポートします。"
  },
  "gemini-1.5-flash-002": {
    "description": "Gemini 1.5 Flash 002は効率的なマルチモーダルモデルで、幅広いアプリケーションの拡張をサポートしています。"
  },
  "gemini-1.5-flash-8b": {
    "description": "Gemini 1.5 Flash 8Bは、高効率のマルチモーダルモデルで、幅広いアプリケーションの拡張をサポートしています。"
  },
  "gemini-1.5-flash-8b-exp-0924": {
    "description": "Gemini 1.5 Flash 8B 0924は最新の実験モデルで、テキストおよびマルチモーダルのユースケースにおいて顕著な性能向上を実現しています。"
  },
  "gemini-1.5-flash-exp-0827": {
    "description": "Gemini 1.5 Flash 0827は、最適化されたマルチモーダル処理能力を提供し、多様な複雑なタスクシナリオに適用可能です。"
  },
  "gemini-1.5-flash-latest": {
    "description": "Gemini 1.5 Flashは、Googleの最新のマルチモーダルAIモデルであり、高速処理能力を備え、テキスト、画像、動画の入力をサポートし、さまざまなタスクの効率的な拡張に適しています。"
  },
  "gemini-1.5-pro-001": {
    "description": "Gemini 1.5 Pro 001は、拡張可能なマルチモーダルAIソリューションであり、幅広い複雑なタスクをサポートします。"
  },
  "gemini-1.5-pro-002": {
    "description": "Gemini 1.5 Pro 002は最新の生産準備モデルで、特に数学、長いコンテキスト、視覚タスクにおいて質の高い出力を提供し、顕著な向上を見せています。"
  },
  "gemini-1.5-pro-exp-0801": {
    "description": "Gemini 1.5 Pro 0801は、優れたマルチモーダル処理能力を提供し、アプリケーション開発により大きな柔軟性をもたらします。"
  },
  "gemini-1.5-pro-exp-0827": {
    "description": "Gemini 1.5 Pro 0827は、最新の最適化技術を組み合わせ、より効率的なマルチモーダルデータ処理能力をもたらします。"
  },
  "gemini-1.5-pro-latest": {
    "description": "Gemini 1.5 Proは、最大200万トークンをサポートする中型マルチモーダルモデルの理想的な選択肢であり、複雑なタスクに対する多面的なサポートを提供します。"
  },
  "gemini-2.0-flash": {
    "description": "Gemini 2.0 Flashは、卓越した速度、ネイティブツールの使用、マルチモーダル生成、1Mトークンのコンテキストウィンドウを含む次世代の機能と改善を提供します。"
  },
  "gemini-2.0-flash-001": {
    "description": "Gemini 2.0 Flashは、卓越した速度、ネイティブツールの使用、マルチモーダル生成、1Mトークンのコンテキストウィンドウを含む次世代の機能と改善を提供します。"
  },
  "gemini-2.0-flash-lite-preview-02-05": {
    "description": "コスト効率と低遅延を目指して最適化されたGemini 2.0 Flashモデルです。"
  },
  "gemini-2.0-flash-thinking-exp-01-21": {
    "description": "Gemini 2.0 Flash Expは、Googleの最新の実験的なマルチモーダルAIモデルであり、次世代の機能、卓越した速度、ネイティブツールの呼び出し、マルチモーダル生成を備えています。"
  },
  "gemini-2.0-pro-exp-02-05": {
    "description": "Gemini 2.0 Pro Experimentalは、Googleの最新の実験的なマルチモーダルAIモデルで、歴史的なバージョンと比較して品質が向上しています。特に、世界の知識、コード、長いコンテキストにおいて顕著です。"
  },
  "gemma-7b-it": {
    "description": "Gemma 7Bは、中小規模のタスク処理に適しており、コスト効果を兼ね備えています。"
  },
  "gemma2": {
    "description": "Gemma 2は、Googleが提供する高効率モデルであり、小型アプリケーションから複雑なデータ処理まで、さまざまなアプリケーションシーンをカバーしています。"
  },
  "gemma2-9b-it": {
    "description": "Gemma 2 9Bは、特定のタスクとツール統合のために最適化されたモデルです。"
  },
  "gemma2:27b": {
    "description": "Gemma 2は、Googleが提供する高効率モデルであり、小型アプリケーションから複雑なデータ処理まで、さまざまなアプリケーションシーンをカバーしています。"
  },
  "gemma2:2b": {
    "description": "Gemma 2は、Googleが提供する高効率モデルであり、小型アプリケーションから複雑なデータ処理まで、さまざまなアプリケーションシーンをカバーしています。"
  },
  "generalv3": {
    "description": "Spark Proは専門分野に最適化された高性能な大言語モデルで、数学、プログラミング、医療、教育などの複数の分野に特化し、ネットワーク検索や内蔵の天気、日付などのプラグインをサポートします。最適化されたモデルは、複雑な知識問答、言語理解、高度なテキスト創作において優れたパフォーマンスと高効率を示し、専門的なアプリケーションシーンに最適な選択肢です。"
  },
  "generalv3.5": {
    "description": "Spark3.5 Maxは機能が最も充実したバージョンで、ネットワーク検索や多くの内蔵プラグインをサポートします。全面的に最適化されたコア能力、システムロール設定、関数呼び出し機能により、さまざまな複雑なアプリケーションシーンでのパフォーマンスが非常に優れています。"
  },
  "glm-4": {
    "description": "GLM-4は2024年1月にリリースされた旧フラッグシップバージョンで、現在はより強力なGLM-4-0520に取って代わられています。"
  },
  "glm-4-0520": {
    "description": "GLM-4-0520は最新のモデルバージョンで、高度に複雑で多様なタスクのために設計され、優れたパフォーマンスを発揮します。"
  },
  "glm-4-9b-chat": {
    "description": "GLM-4-9B-Chatは、意味、数学、推論、コード、知識などの多方面で高い性能を示しています。また、ウェブブラウジング、コード実行、カスタムツール呼び出し、長文推論を備えています。日本語、韓国語、ドイツ語を含む26の言語をサポートしています。"
  },
  "glm-4-air": {
    "description": "GLM-4-Airはコストパフォーマンスが高いバージョンで、GLM-4に近い性能を提供し、高速かつ手頃な価格です。"
  },
  "glm-4-airx": {
    "description": "GLM-4-AirXはGLM-4-Airの効率的なバージョンで、推論速度はその2.6倍に達します。"
  },
  "glm-4-alltools": {
    "description": "GLM-4-AllToolsは、複雑な指示計画とツール呼び出しをサポートするために最適化された多機能エージェントモデルで、ネットサーフィン、コード解釈、テキスト生成などの多タスク実行に適しています。"
  },
  "glm-4-flash": {
    "description": "GLM-4-Flashはシンプルなタスクを処理するのに理想的な選択肢で、最も速く、最も手頃な価格です。"
  },
  "glm-4-flashx": {
    "description": "GLM-4-FlashXはFlashの強化版で、超高速の推論速度を誇ります。"
  },
  "glm-4-long": {
    "description": "GLM-4-Longは超長文入力をサポートし、記憶型タスクや大規模文書処理に適しています。"
  },
  "glm-4-plus": {
    "description": "GLM-4-Plusは高い知能を持つフラッグシップモデルで、長文や複雑なタスクを処理する能力が強化され、全体的なパフォーマンスが向上しています。"
  },
  "glm-4v": {
    "description": "GLM-4Vは強力な画像理解と推論能力を提供し、さまざまな視覚タスクをサポートします。"
  },
  "glm-4v-flash": {
    "description": "GLM-4V-Flashは、高効率の単一画像理解に特化しており、リアルタイム画像分析やバッチ画像処理などの迅速な画像解析のシーンに適しています。"
  },
  "glm-4v-plus": {
    "description": "GLM-4V-Plusは動画コンテンツや複数の画像を理解する能力を持ち、マルチモーダルタスクに適しています。"
  },
  "glm-zero-preview": {
    "description": "GLM-Zero-Previewは、強力な複雑な推論能力を備え、論理推論、数学、プログラミングなどの分野で優れたパフォーマンスを発揮します。"
  },
  "google/gemini-2.0-flash-001": {
    "description": "Gemini 2.0 Flashは、卓越した速度、ネイティブツールの使用、マルチモーダル生成、1Mトークンのコンテキストウィンドウを含む次世代の機能と改善を提供します。"
  },
  "google/gemini-2.0-pro-exp-02-05:free": {
    "description": "Gemini 2.0 Pro Experimentalは、Googleの最新の実験的なマルチモーダルAIモデルで、歴史的なバージョンと比較して品質が向上しています。特に、世界の知識、コード、長いコンテキストにおいて顕著です。"
  },
  "google/gemini-flash-1.5": {
    "description": "Gemini 1.5 Flashは、最適化されたマルチモーダル処理能力を提供し、さまざまな複雑なタスクシナリオに適しています。"
  },
  "google/gemini-pro-1.5": {
    "description": "Gemini 1.5 Proは、最新の最適化技術を組み合わせて、より効率的なマルチモーダルデータ処理能力を実現します。"
  },
  "google/gemma-2-27b": {
    "description": "Gemma 2はGoogleが提供する効率的なモデルで、小型アプリケーションから複雑なデータ処理まで、さまざまなアプリケーションシナリオをカバーしています。"
  },
  "google/gemma-2-27b-it": {
    "description": "Gemma 2は、軽量化と高効率のデザイン理念を継承しています。"
  },
  "google/gemma-2-2b-it": {
    "description": "Googleの軽量指示調整モデル"
  },
  "google/gemma-2-9b": {
    "description": "Gemma 2はGoogleが提供する効率的なモデルで、小型アプリケーションから複雑なデータ処理まで、さまざまなアプリケーションシナリオをカバーしています。"
  },
  "google/gemma-2-9b-it": {
    "description": "Gemma 2は、Googleの軽量オープンソーステキストモデルシリーズです。"
  },
  "google/gemma-2-9b-it:free": {
    "description": "Gemma 2はGoogleの軽量化されたオープンソーステキストモデルシリーズです。"
  },
  "google/gemma-2b-it": {
    "description": "Gemma Instruct (2B)は、基本的な指示処理能力を提供し、軽量アプリケーションに適しています。"
  },
  "gpt-3.5-turbo": {
    "description": "GPT 3.5 Turboは、さまざまなテキスト生成と理解タスクに適しており、現在はgpt-3.5-turbo-0125を指しています。"
  },
  "gpt-3.5-turbo-0125": {
    "description": "GPT 3.5 Turboは、さまざまなテキスト生成と理解タスクに適しており、現在はgpt-3.5-turbo-0125を指しています。"
  },
  "gpt-3.5-turbo-1106": {
    "description": "GPT 3.5 Turboは、さまざまなテキスト生成と理解タスクに適しており、現在はgpt-3.5-turbo-0125を指しています。"
  },
  "gpt-3.5-turbo-instruct": {
    "description": "GPT 3.5 Turboは、さまざまなテキスト生成と理解タスクに適しており、現在はgpt-3.5-turbo-0125を指しています。"
  },
  "gpt-35-turbo": {
    "description": "GPT 3.5 Turboは、OpenAIが提供する効率的なモデルで、チャットやテキスト生成タスクに適しており、並行関数呼び出しをサポートしています。"
  },
  "gpt-35-turbo-16k": {
    "description": "GPT 3.5 Turbo 16kは、高容量のテキスト生成モデルで、複雑なタスクに適しています。"
  },
  "gpt-4": {
    "description": "GPT-4は、より大きなコンテキストウィンドウを提供し、より長いテキスト入力を処理できるため、広範な情報統合やデータ分析が必要なシナリオに適しています。"
  },
  "gpt-4-0125-preview": {
    "description": "最新のGPT-4 Turboモデルは視覚機能を備えています。現在、視覚リクエストはJSON形式と関数呼び出しを使用して行うことができます。GPT-4 Turboは、マルチモーダルタスクに対してコスト効率の高いサポートを提供する強化版です。正確性と効率のバランスを取り、リアルタイムのインタラクションが必要なアプリケーションシナリオに適しています。"
  },
  "gpt-4-0613": {
    "description": "GPT-4は、より大きなコンテキストウィンドウを提供し、より長いテキスト入力を処理できるため、広範な情報統合やデータ分析が必要なシナリオに適しています。"
  },
  "gpt-4-1106-preview": {
    "description": "最新のGPT-4 Turboモデルは視覚機能を備えています。現在、視覚リクエストはJSON形式と関数呼び出しを使用して行うことができます。GPT-4 Turboは、マルチモーダルタスクに対してコスト効率の高いサポートを提供する強化版です。正確性と効率のバランスを取り、リアルタイムのインタラクションが必要なアプリケーションシナリオに適しています。"
  },
  "gpt-4-32k": {
    "description": "GPT-4は、より大きなコンテキストウィンドウを提供し、より長いテキスト入力を処理できるため、広範な情報統合やデータ分析が必要なシナリオに適しています。"
  },
  "gpt-4-32k-0613": {
    "description": "GPT-4は、より大きなコンテキストウィンドウを提供し、より長いテキスト入力を処理できるため、広範な情報統合やデータ分析が必要なシナリオに適しています。"
  },
  "gpt-4-turbo": {
    "description": "最新のGPT-4 Turboモデルは視覚機能を備えています。現在、視覚リクエストはJSON形式と関数呼び出しを使用して行うことができます。GPT-4 Turboは、マルチモーダルタスクに対してコスト効率の高いサポートを提供する強化版です。正確性と効率のバランスを取り、リアルタイムのインタラクションが必要なアプリケーションシナリオに適しています。"
  },
  "gpt-4-turbo-2024-04-09": {
    "description": "最新のGPT-4 Turboモデルは視覚機能を備えています。現在、視覚リクエストはJSON形式と関数呼び出しを使用して行うことができます。GPT-4 Turboは、マルチモーダルタスクに対してコスト効率の高いサポートを提供する強化版です。正確性と効率のバランスを取り、リアルタイムのインタラクションが必要なアプリケーションシナリオに適しています。"
  },
  "gpt-4-turbo-preview": {
    "description": "最新のGPT-4 Turboモデルは視覚機能を備えています。現在、視覚リクエストはJSON形式と関数呼び出しを使用して行うことができます。GPT-4 Turboは、マルチモーダルタスクに対してコスト効率の高いサポートを提供する強化版です。正確性と効率のバランスを取り、リアルタイムのインタラクションが必要なアプリケーションシナリオに適しています。"
  },
  "gpt-4-vision-preview": {
    "description": "最新のGPT-4 Turboモデルは視覚機能を備えています。現在、視覚リクエストはJSON形式と関数呼び出しを使用して行うことができます。GPT-4 Turboは、マルチモーダルタスクに対してコスト効率の高いサポートを提供する強化版です。正確性と効率のバランスを取り、リアルタイムのインタラクションが必要なアプリケーションシナリオに適しています。"
  },
  "gpt-4o": {
    "description": "ChatGPT-4oは、リアルタイムで更新される動的モデルで、常に最新のバージョンを維持します。強力な言語理解と生成能力を組み合わせており、顧客サービス、教育、技術サポートなどの大規模なアプリケーションシナリオに適しています。"
  },
  "gpt-4o-2024-05-13": {
    "description": "ChatGPT-4oは、リアルタイムで更新される動的モデルで、常に最新のバージョンを維持します。強力な言語理解と生成能力を組み合わせており、顧客サービス、教育、技術サポートなどの大規模なアプリケーションシナリオに適しています。"
  },
  "gpt-4o-2024-08-06": {
    "description": "ChatGPT-4oは、リアルタイムで更新される動的モデルで、常に最新のバージョンを維持します。強力な言語理解と生成能力を組み合わせており、顧客サービス、教育、技術サポートなどの大規模なアプリケーションシナリオに適しています。"
  },
  "gpt-4o-2024-11-20": {
    "description": "ChatGPT-4oは動的モデルで、リアルタイムで更新され、常に最新バージョンを保持します。 powerfulな言語理解と生成能力を組み合わせており、カスタマーサービス、教育、技術サポートなどの大規模なアプリケーションに適しています。"
  },
  "gpt-4o-audio-preview": {
    "description": "GPT-4o Audio モデル、音声の入力と出力をサポート"
  },
  "gpt-4o-mini": {
    "description": "GPT-4o miniは、OpenAIがGPT-4 Omniの後に発表した最新のモデルで、画像とテキストの入力をサポートし、テキストを出力します。最先端の小型モデルとして、最近の他の先進モデルよりもはるかに安価で、GPT-3.5 Turboよりも60%以上安価です。最先端の知能を維持しつつ、コストパフォーマンスが大幅に向上しています。GPT-4o miniはMMLUテストで82%のスコアを獲得し、現在チャットの好みではGPT-4よりも高い評価を得ています。"
  },
  "gpt-4o-mini-realtime-preview": {
    "description": "GPT-4o-miniリアルタイムバージョン、音声とテキストのリアルタイム入力と出力をサポート"
  },
  "gpt-4o-realtime-preview": {
    "description": "GPT-4oリアルタイムバージョン、音声とテキストのリアルタイム入力と出力をサポート"
  },
  "gpt-4o-realtime-preview-2024-10-01": {
    "description": "GPT-4oリアルタイムバージョン、音声とテキストのリアルタイム入力と出力をサポート"
  },
  "gpt-4o-realtime-preview-2024-12-17": {
    "description": "GPT-4oリアルタイムバージョン、音声とテキストのリアルタイム入力と出力をサポート"
  },
  "grok-2-1212": {
    "description": "このモデルは、精度、指示の遵守、そして多言語能力において改善されています。"
  },
  "grok-2-vision-1212": {
    "description": "このモデルは、精度、指示の遵守、そして多言語能力において改善されています。"
  },
  "grok-beta": {
    "description": "Grok 2と同等の性能を持ちながら、より高い効率、速度、機能を備えています。"
  },
  "grok-vision-beta": {
    "description": "最新の画像理解モデルで、文書、グラフ、スクリーンショット、写真など、さまざまな視覚情報を処理できます。"
  },
  "gryphe/mythomax-l2-13b": {
    "description": "MythoMax l2 13Bは複数のトップモデルを統合した創造性と知性を兼ね備えた言語モデルです。"
  },
  "hunyuan-code": {
    "description": "混元の最新のコード生成モデルで、200Bの高品質コードデータで基盤モデルを増強し、半年間の高品質SFTデータトレーニングを経て、コンテキストウィンドウの長さが8Kに増加しました。5つの主要言語のコード生成自動評価指標で上位に位置し、5つの言語における10項目の総合コードタスクの人工高品質評価で、パフォーマンスは第一梯隊にあります。"
  },
  "hunyuan-functioncall": {
    "description": "混元の最新のMOEアーキテクチャFunctionCallモデルで、高品質のFunctionCallデータトレーニングを経て、コンテキストウィンドウは32Kに達し、複数の次元の評価指標でリーダーシップを発揮しています。"
  },
  "hunyuan-large": {
    "description": "Hunyuan-largeモデルの総パラメータ数は約389B、活性化パラメータ数は約52Bで、現在業界で最大のパラメータ規模を持ち、最も優れた効果を持つTransformerアーキテクチャのオープンソースMoEモデル。"
  },
  "hunyuan-large-longcontext": {
    "description": "文書要約や文書問答などの長文タスクを得意とし、一般的なテキスト生成タスクの処理能力も備えている。長文の分析と生成において優れたパフォーマンスを発揮し、複雑で詳細な長文内容の処理要求に効果的に対応できる。"
  },
  "hunyuan-lite": {
    "description": "MOE構造にアップグレードされ、コンテキストウィンドウは256kで、NLP、コード、数学、業界などの多くの評価セットで多くのオープンソースモデルをリードしています。"
  },
  "hunyuan-lite-vision": {
    "description": "混元最新の7Bマルチモーダルモデル、コンテキストウィンドウ32K、中英文シーンのマルチモーダル対話、画像物体認識、文書表理解、マルチモーダル数学などをサポートし、複数の次元で評価指標が7B競合モデルを上回る。"
  },
  "hunyuan-pro": {
    "description": "万億規模のパラメータを持つMOE-32K長文モデルです。さまざまなベンチマークで絶対的なリーダーシップを達成し、複雑な指示や推論、複雑な数学能力を備え、functioncallをサポートし、多言語翻訳、金融、法律、医療などの分野で重点的に最適化されています。"
  },
  "hunyuan-role": {
    "description": "混元の最新のロールプレイングモデルで、混元公式の精緻なトレーニングによって開発されたロールプレイングモデルで、混元モデルとロールプレイングシナリオデータセットを組み合わせて増強され、ロールプレイングシナリオにおいてより良い基本的な効果を持っています。"
  },
  "hunyuan-standard": {
    "description": "より優れたルーティング戦略を採用し、負荷分散と専門家の収束の問題を緩和しました。長文に関しては、大海捞針指標が99.9%に達しています。MOE-32Kはコストパフォーマンスが相対的に高く、効果と価格のバランスを取りながら、長文入力の処理を実現します。"
  },
  "hunyuan-standard-256K": {
    "description": "より優れたルーティング戦略を採用し、負荷分散と専門家の収束の問題を緩和しました。長文に関しては、大海捞針指標が99.9%に達しています。MOE-256Kは長さと効果の面でさらに突破し、入力可能な長さを大幅に拡張しました。"
  },
  "hunyuan-standard-vision": {
    "description": "混元最新のマルチモーダルモデルで、多言語での応答をサポートし、中英文能力が均衡している。"
  },
  "hunyuan-translation": {
    "description": "中国語、英語、日本語、フランス語、ポルトガル語、スペイン語、トルコ語、ロシア語、アラビア語、韓国語、イタリア語、ドイツ語、ベトナム語、マレー語、インドネシア語の15言語の相互翻訳をサポートし、多シーン翻訳評価セットに基づく自動評価COMETスコアを使用して、十数の一般的な言語間の翻訳能力が市場の同規模モデルを全体的に上回っています。"
  },
  "hunyuan-translation-lite": {
    "description": "混元翻訳モデルは自然言語の対話式翻訳をサポートし、中国語、英語、日本語、フランス語、ポルトガル語、スペイン語、トルコ語、ロシア語、アラビア語、韓国語、イタリア語、ドイツ語、ベトナム語、マレー語、インドネシア語の15言語の相互翻訳をサポートしています。"
  },
  "hunyuan-turbo": {
    "description": "混元の新世代大規模言語モデルのプレビュー版で、全く新しい混合専門家モデル（MoE）構造を採用し、hunyuan-proに比べて推論効率が向上し、パフォーマンスも強化されています。"
  },
  "hunyuan-turbo-20241120": {
    "description": "hunyuan-turbo 2024年11月20日の固定バージョンで、hunyuan-turboとhunyuan-turbo-latestの間に位置するバージョン。"
  },
  "hunyuan-turbo-20241223": {
    "description": "このバージョンの最適化：データ指令のスケーリングにより、モデルの汎用的な一般化能力を大幅に向上；数学、コード、論理推論能力を大幅に向上；テキスト理解と語彙理解に関連する能力を最適化；テキスト作成の内容生成の質を最適化。"
  },
  "hunyuan-turbo-latest": {
    "description": "汎用体験の最適化、NLP理解、テキスト作成、雑談、知識問答、翻訳、分野などを含む；擬人性を向上させ、モデルの感情知能を最適化；意図が曖昧な時のモデルの能動的な明確化能力を向上；語彙解析に関する問題の処理能力を向上；創作の質とインタラクティブ性を向上；多段階体験を向上。"
  },
  "hunyuan-turbo-vision": {
    "description": "混元の次世代視覚言語フラッグシップ大モデルで、全く新しい混合専門家モデル（MoE）構造を採用し、画像とテキストの理解に関連する基礎認識、コンテンツ作成、知識問答、分析推論などの能力が前世代モデルに比べて全面的に向上。"
  },
  "hunyuan-vision": {
    "description": "混元の最新のマルチモーダルモデルで、画像とテキストの入力をサポートし、テキストコンテンツを生成します。"
  },
  "internlm/internlm2_5-20b-chat": {
    "description": "革新的なオープンソースモデルInternLM2.5は、大規模なパラメータを通じて対話のインテリジェンスを向上させました。"
  },
  "internlm/internlm2_5-7b-chat": {
    "description": "InternLM2.5は多様なシーンでのインテリジェントな対話ソリューションを提供します。"
  },
  "internlm2-pro-chat": {
    "description": "私たちがまだ維持している旧バージョンのモデルで、7B、20Bのさまざまなモデルパラメータ量が選択可能です。"
  },
  "internlm2.5-latest": {
    "description": "私たちの最新のモデルシリーズで、卓越した推論性能を持ち、1Mのコンテキスト長をサポートし、より強力な指示追従とツール呼び出し能力を備えています。"
  },
  "internlm3-latest": {
    "description": "私たちの最新のモデルシリーズは、卓越した推論性能を持ち、同等のオープンソースモデルの中でリーダーシップを発揮しています。デフォルトで最新のInternLM3シリーズモデルを指します。"
  },
  "jina-deepsearch-v1": {
    "description": "深層検索は、ウェブ検索、読解、推論を組み合わせて、包括的な調査を行います。これは、あなたの研究タスクを受け入れる代理人として考えることができ、広範な検索を行い、何度も反復してから答えを提供します。このプロセスには、継続的な研究、推論、さまざまな視点からの問題解決が含まれます。これは、事前に訓練されたデータから直接答えを生成する標準的な大規模モデルや、一度きりの表面的な検索に依存する従来のRAGシステムとは根本的に異なります。"
  },
  "kimi-latest": {
    "description": "Kimi スマートアシスタント製品は最新の Kimi 大モデルを使用しており、まだ安定していない機能が含まれている可能性があります。画像理解をサポートし、リクエストのコンテキストの長さに応じて 8k/32k/128k モデルを請求モデルとして自動的に選択します。"
  },
  "learnlm-1.5-pro-experimental": {
    "description": "LearnLMは、学習科学の原則に従って訓練された実験的なタスク特化型言語モデルで、教育や学習のシーンでシステムの指示に従い、専門的なメンターとして機能します。"
  },
  "lite": {
    "description": "Spark Liteは軽量な大規模言語モデルで、非常に低い遅延と高い処理能力を備えています。完全に無料でオープンであり、リアルタイムのオンライン検索機能をサポートしています。その迅速な応答特性により、低算力デバイスでの推論アプリケーションやモデルの微調整において優れたパフォーマンスを発揮し、特に知識問答、コンテンツ生成、検索シーンにおいて優れたコストパフォーマンスとインテリジェントな体験を提供します。"
  },
  "llama-3.1-70b-versatile": {
    "description": "Llama 3.1 70Bは、より強力なAI推論能力を提供し、複雑なアプリケーションに適しており、非常に多くの計算処理をサポートし、高効率と精度を保証します。"
  },
  "llama-3.1-8b-instant": {
    "description": "Llama 3.1 8Bは、高効率モデルであり、迅速なテキスト生成能力を提供し、大規模な効率とコスト効果が求められるアプリケーションシナリオに非常に適しています。"
  },
  "llama-3.1-sonar-huge-128k-online": {
    "description": "Llama 3.1 Sonar Huge Onlineモデルは、405Bパラメータを持ち、約127,000トークンのコンテキスト長をサポートし、複雑なオンラインチャットアプリケーション用に設計されています。"
  },
  "llama-3.1-sonar-large-128k-online": {
    "description": "Llama 3.1 Sonar Large Onlineモデルは、70Bパラメータを持ち、約127,000トークンのコンテキスト長をサポートし、高容量で多様なチャットタスクに適しています。"
  },
  "llama-3.1-sonar-small-128k-online": {
    "description": "Llama 3.1 Sonar Small Onlineモデルは、8Bパラメータを持ち、約127,000トークンのコンテキスト長をサポートし、オンラインチャット用に設計されており、さまざまなテキストインタラクションを効率的に処理できます。"
  },
  "llama-3.2-11b-vision-instruct": {
    "description": "高解像度画像で優れた画像推論能力を発揮し、視覚理解アプリケーションに適しています。"
  },
  "llama-3.2-11b-vision-preview": {
    "description": "Llama 3.2は、視覚データとテキストデータを組み合わせたタスクを処理することを目的としています。画像の説明や視覚的質問応答などのタスクで優れたパフォーマンスを発揮し、言語生成と視覚推論の間のギャップを埋めます。"
  },
  "llama-3.2-90b-vision-instruct": {
    "description": "視覚理解エージェントアプリケーション向けの高度な画像推論能力を提供します。"
  },
  "llama-3.2-90b-vision-preview": {
    "description": "Llama 3.2は、視覚データとテキストデータを組み合わせたタスクを処理することを目的としています。画像の説明や視覚的質問応答などのタスクで優れたパフォーマンスを発揮し、言語生成と視覚推論の間のギャップを埋めます。"
  },
  "llama-3.3-70b-instruct": {
    "description": "Llama 3.3は、Llamaシリーズの最先端の多言語オープンソース大規模言語モデルで、非常に低コストで405Bモデルに匹敵する性能を体験できます。Transformer構造に基づき、監視付き微調整（SFT）と人間のフィードバックによる強化学習（RLHF）を通じて有用性と安全性を向上させています。その指示調整バージョンは多言語対話に最適化されており、複数の業界ベンチマークで多くのオープンソースおよびクローズドチャットモデルを上回る性能を発揮します。知識のカットオフ日は2023年12月です。"
  },
  "llama-3.3-70b-versatile": {
    "description": "Meta Llama 3.3は、70B（テキスト入力/テキスト出力）の事前学習と指示調整による生成モデルを持つ多言語大規模言語モデル（LLM）です。Llama 3.3の指示調整済みのプレーンテキストモデルは、多言語の対話ユースケースに最適化されており、一般的な業界ベンチマークで多くの利用可能なオープンソースおよびクローズドチャットモデルを上回っています。"
  },
  "llama3-70b-8192": {
    "description": "Meta Llama 3 70Bは、比類のない複雑性処理能力を提供し、高要求プロジェクトに特化しています。"
  },
  "llama3-8b-8192": {
    "description": "Meta Llama 3 8Bは、優れた推論性能を提供し、多様なシーンのアプリケーションニーズに適しています。"
  },
  "llama3-groq-70b-8192-tool-use-preview": {
    "description": "Llama 3 Groq 70B Tool Useは、強力なツール呼び出し能力を提供し、複雑なタスクの効率的な処理をサポートします。"
  },
  "llama3-groq-8b-8192-tool-use-preview": {
    "description": "Llama 3 Groq 8B Tool Useは、高効率なツール使用に最適化されたモデルであり、迅速な並列計算をサポートします。"
  },
  "llama3.1": {
    "description": "Llama 3.1は、Metaが提供する先進的なモデルであり、最大405Bのパラメータをサポートし、複雑な対話、多言語翻訳、データ分析の分野で応用できます。"
  },
  "llama3.1:405b": {
    "description": "Llama 3.1は、Metaが提供する先進的なモデルであり、最大405Bのパラメータをサポートし、複雑な対話、多言語翻訳、データ分析の分野で応用できます。"
  },
  "llama3.1:70b": {
    "description": "Llama 3.1は、Metaが提供する先進的なモデルであり、最大405Bのパラメータをサポートし、複雑な対話、多言語翻訳、データ分析の分野で応用できます。"
  },
  "llava": {
    "description": "LLaVAは、視覚エンコーダーとVicunaを組み合わせたマルチモーダルモデルであり、強力な視覚と言語理解を提供します。"
  },
  "llava-v1.5-7b-4096-preview": {
    "description": "LLaVA 1.5 7Bは、視覚処理能力を融合させ、視覚情報入力を通じて複雑な出力を生成します。"
  },
  "llava:13b": {
    "description": "LLaVAは、視覚エンコーダーとVicunaを組み合わせたマルチモーダルモデルであり、強力な視覚と言語理解を提供します。"
  },
  "llava:34b": {
    "description": "LLaVAは、視覚エンコーダーとVicunaを組み合わせたマルチモーダルモデルであり、強力な視覚と言語理解を提供します。"
  },
  "mathstral": {
    "description": "MathΣtralは、科学研究と数学推論のために設計されており、効果的な計算能力と結果の解釈を提供します。"
  },
  "max-32k": {
    "description": "Spark Max 32Kは大規模なコンテキスト処理能力を備え、より強力なコンテキスト理解と論理推論能力を持ち、32Kトークンのテキスト入力をサポートします。長文書の読解やプライベートな知識問答などのシーンに適しています。"
  },
  "meta-llama-3-70b-instruct": {
    "description": "推論、コーディング、広範な言語アプリケーションに優れた70億パラメータの強力なモデルです。"
  },
  "meta-llama-3-8b-instruct": {
    "description": "対話とテキスト生成タスクに最適化された多用途の80億パラメータモデルです。"
  },
  "meta-llama-3.1-405b-instruct": {
    "description": "Llama 3.1の指示調整されたテキスト専用モデルは、多言語対話のユースケースに最適化されており、一般的な業界ベンチマークで多くのオープンソースおよびクローズドチャットモデルを上回ります。"
  },
  "meta-llama-3.1-70b-instruct": {
    "description": "Llama 3.1の指示調整されたテキスト専用モデルは、多言語対話のユースケースに最適化されており、一般的な業界ベンチマークで多くのオープンソースおよびクローズドチャットモデルを上回ります。"
  },
  "meta-llama-3.1-8b-instruct": {
    "description": "Llama 3.1の指示調整されたテキスト専用モデルは、多言語対話のユースケースに最適化されており、一般的な業界ベンチマークで多くのオープンソースおよびクローズドチャットモデルを上回ります。"
  },
  "meta-llama/Llama-2-13b-chat-hf": {
    "description": "LLaMA-2 Chat (13B)は、優れた言語処理能力と素晴らしいインタラクション体験を提供します。"
  },
  "meta-llama/Llama-2-70b-hf": {
    "description": "LLaMA-2は優れた言語処理能力と素晴らしいインタラクティブ体験を提供します。"
  },
  "meta-llama/Llama-3-70b-chat-hf": {
    "description": "LLaMA-3 Chat (70B)は、強力なチャットモデルであり、複雑な対話ニーズをサポートします。"
  },
  "meta-llama/Llama-3-8b-chat-hf": {
    "description": "LLaMA-3 Chat (8B)は、多言語サポートを提供し、豊富な分野知識をカバーしています。"
  },
  "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo": {
    "description": "LLaMA 3.2は視覚データとテキストデータを組み合わせたタスクを処理することを目的としています。画像の説明や視覚的質問応答などのタスクで優れた性能を発揮し、言語生成と視覚推論の間のギャップを埋めます。"
  },
  "meta-llama/Llama-3.2-3B-Instruct-Turbo": {
    "description": "LLaMA 3.2は視覚データとテキストデータを組み合わせたタスクを処理することを目的としています。画像の説明や視覚的質問応答などのタスクで優れた性能を発揮し、言語生成と視覚推論の間のギャップを埋めます。"
  },
  "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo": {
    "description": "LLaMA 3.2は視覚データとテキストデータを組み合わせたタスクを処理することを目的としています。画像の説明や視覚的質問応答などのタスクで優れた性能を発揮し、言語生成と視覚推論の間のギャップを埋めます。"
  },
  "meta-llama/Llama-3.3-70B-Instruct": {
    "description": "Llama 3.3はLlamaシリーズの最先端の多言語オープンソース大規模言語モデルで、非常に低コストで405Bモデルに匹敵する性能を体験できます。Transformer構造に基づき、監視付き微調整（SFT）と人間のフィードバック強化学習（RLHF）を通じて有用性と安全性を向上させています。その指示調整バージョンは多言語対話に最適化されており、複数の業界ベンチマークで多くのオープンソースおよびクローズドチャットモデルを上回る性能を発揮します。知識のカットオフ日は2023年12月です"
  },
  "meta-llama/Llama-3.3-70B-Instruct-Turbo": {
    "description": "Meta Llama 3.3の多言語大規模言語モデル（LLM）は、70B（テキスト入力/テキスト出力）の事前訓練と指示調整生成モデルです。Llama 3.3の指示調整された純粋なテキストモデルは、多言語対話のユースケースに最適化されており、一般的な業界ベンチマークで多くの利用可能なオープンソースおよびクローズドチャットモデルを上回っています。"
  },
  "meta-llama/Llama-Vision-Free": {
    "description": "LLaMA 3.2は視覚データとテキストデータを組み合わせたタスクを処理することを目的としています。画像の説明や視覚的質問応答などのタスクで優れた性能を発揮し、言語生成と視覚推論の間のギャップを埋めます。"
  },
  "meta-llama/Meta-Llama-3-70B-Instruct-Lite": {
    "description": "Llama 3 70B Instruct Liteは、高効率と低遅延が求められる環境に適しています。"
  },
  "meta-llama/Meta-Llama-3-70B-Instruct-Turbo": {
    "description": "Llama 3 70B Instruct Turboは、卓越した言語理解と生成能力を提供し、最も厳しい計算タスクに適しています。"
  },
  "meta-llama/Meta-Llama-3-8B-Instruct-Lite": {
    "description": "Llama 3 8B Instruct Liteは、リソースが制限された環境に適しており、優れたバランス性能を提供します。"
  },
  "meta-llama/Meta-Llama-3-8B-Instruct-Turbo": {
    "description": "Llama 3 8B Instruct Turboは、高効率の大規模言語モデルであり、幅広いアプリケーションシナリオをサポートします。"
  },
  "meta-llama/Meta-Llama-3.1-405B-Instruct": {
    "description": "LLaMA 3.1 405Bは事前学習と指示調整の強力なモデルです。"
  },
  "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo": {
    "description": "405BのLlama 3.1 Turboモデルは、大規模データ処理のために超大容量のコンテキストサポートを提供し、超大規模な人工知能アプリケーションで優れたパフォーマンスを発揮します。"
  },
  "meta-llama/Meta-Llama-3.1-70B": {
    "description": "Llama 3.1はMetaが提供する先進的なモデルで、最大405Bのパラメータをサポートし、複雑な対話、多言語翻訳、データ分析の分野で利用できます。"
  },
  "meta-llama/Meta-Llama-3.1-70B-Instruct": {
    "description": "LLaMA 3.1 70Bは多言語の高効率な対話サポートを提供します。"
  },
  "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo": {
    "description": "Llama 3.1 70Bモデルは微調整されており、高負荷アプリケーションに適しており、FP8に量子化されてより効率的な計算能力と精度を提供し、複雑なシナリオでの卓越したパフォーマンスを保証します。"
  },
  "meta-llama/Meta-Llama-3.1-8B-Instruct": {
    "description": "LLaMA 3.1は多言語サポートを提供し、業界をリードする生成モデルの一つです。"
  },
  "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo": {
    "description": "Llama 3.1 8BモデルはFP8量子化を採用し、最大131,072のコンテキストトークンをサポートし、オープンソースモデルの中で際立っており、複雑なタスクに適しており、多くの業界ベンチマークを上回る性能を発揮します。"
  },
  "meta-llama/llama-3-70b-instruct": {
    "description": "Llama 3 70B Instructは高品質な対話シーンに最適化されており、さまざまな人間の評価において優れたパフォーマンスを示します。"
  },
  "meta-llama/llama-3-8b-instruct": {
    "description": "Llama 3 8B Instructは高品質な対話シーンに最適化されており、多くのクローズドソースモデルよりも優れた性能を持っています。"
  },
  "meta-llama/llama-3.1-70b-instruct": {
    "description": "Llama 3.1 70B Instructは高品質な対話のために設計されており、人間の評価において優れたパフォーマンスを示し、高いインタラクションシーンに特に適しています。"
  },
  "meta-llama/llama-3.1-8b-instruct": {
    "description": "Llama 3.1 8B InstructはMetaが発表した最新バージョンで、高品質な対話シーンに最適化されており、多くの先進的なクローズドソースモデルを上回る性能を発揮します。"
  },
  "meta-llama/llama-3.1-8b-instruct:free": {
    "description": "LLaMA 3.1は多言語サポートを提供し、業界をリードする生成モデルの一つです。"
  },
  "meta-llama/llama-3.2-11b-vision-instruct": {
    "description": "LLaMA 3.2は、視覚とテキストデータを組み合わせたタスクを処理することを目的としています。画像の説明や視覚的な質問応答などのタスクで優れたパフォーマンスを発揮し、言語生成と視覚推論の間のギャップを超えています。"
  },
  "meta-llama/llama-3.2-90b-vision-instruct": {
    "description": "LLaMA 3.2は、視覚とテキストデータを組み合わせたタスクを処理することを目的としています。画像の説明や視覚的な質問応答などのタスクで優れたパフォーマンスを発揮し、言語生成と視覚推論の間のギャップを超えています。"
  },
  "meta-llama/llama-3.3-70b-instruct": {
    "description": "Llama 3.3は、Llamaシリーズの最先端の多言語オープンソース大規模言語モデルで、非常に低コストで405Bモデルに匹敵する性能を体験できます。Transformer構造に基づき、監視付き微調整（SFT）と人間のフィードバックによる強化学習（RLHF）を通じて有用性と安全性を向上させています。その指示調整バージョンは多言語対話に最適化されており、複数の業界ベンチマークで多くのオープンソースおよびクローズドチャットモデルを上回る性能を発揮します。知識のカットオフ日は2023年12月です。"
  },
  "meta-llama/llama-3.3-70b-instruct:free": {
    "description": "Llama 3.3は、Llamaシリーズの最先端の多言語オープンソース大規模言語モデルで、非常に低コストで405Bモデルに匹敵する性能を体験できます。Transformer構造に基づき、監視付き微調整（SFT）と人間のフィードバックによる強化学習（RLHF）を通じて有用性と安全性を向上させています。その指示調整バージョンは多言語対話に最適化されており、複数の業界ベンチマークで多くのオープンソースおよびクローズドチャットモデルを上回る性能を発揮します。知識のカットオフ日は2023年12月です。"
  },
  "meta.llama3-1-405b-instruct-v1:0": {
    "description": "Meta Llama 3.1 405B Instructは、Llama 3.1 Instructモデルの中で最大かつ最も強力なモデルであり、高度に進化した対話推論および合成データ生成モデルです。また、特定の分野での専門的な継続的な事前トレーニングや微調整の基盤としても使用できます。Llama 3.1が提供する多言語大規模言語モデル（LLMs）は、8B、70B、405Bのサイズ（テキスト入力/出力）を含む、事前トレーニングされた指示調整された生成モデルのセットです。Llama 3.1の指示調整されたテキストモデル（8B、70B、405B）は、多言語対話のユースケースに最適化されており、一般的な業界ベンチマークテストで多くの利用可能なオープンソースチャットモデルを上回っています。Llama 3.1は、さまざまな言語の商業および研究用途に使用されることを目的としています。指示調整されたテキストモデルは、アシスタントのようなチャットに適しており、事前トレーニングモデルはさまざまな自然言語生成タスクに適応できます。Llama 3.1モデルは、他のモデルを改善するためにその出力を利用することもサポートしており、合成データ生成や洗練にも対応しています。Llama 3.1は、最適化されたトランスフォーマーアーキテクチャを使用した自己回帰型言語モデルです。調整されたバージョンは、監視付き微調整（SFT）と人間のフィードバックを伴う強化学習（RLHF）を使用して、人間の助けや安全性に対する好みに適合させています。"
  },
  "meta.llama3-1-70b-instruct-v1:0": {
    "description": "Meta Llama 3.1 70B Instructの更新版で、拡張された128Kのコンテキスト長、多言語性、改善された推論能力を含んでいます。Llama 3.1が提供する多言語大型言語モデル（LLMs）は、8B、70B、405Bのサイズ（テキスト入力/出力）を含む一連の事前トレーニングされた、指示調整された生成モデルです。Llama 3.1の指示調整されたテキストモデル（8B、70B、405B）は、多言語対話用のユースケースに最適化されており、一般的な業界ベンチマークテストで多くの利用可能なオープンソースチャットモデルを超えています。Llama 3.1は多言語の商業および研究用途に使用されることを目的としています。指示調整されたテキストモデルはアシスタントのようなチャットに適しており、事前トレーニングモデルはさまざまな自然言語生成タスクに適応できます。Llama 3.1モデルは、他のモデルを改善するためにその出力を利用することもサポートしており、合成データ生成や精製を含みます。Llama 3.1は最適化されたトランスフォーマーアーキテクチャを使用した自己回帰型言語モデルです。調整版は、監視付き微調整（SFT）と人間のフィードバックを伴う強化学習（RLHF）を使用して、人間の助けや安全性に対する好みに適合させています。"
  },
  "meta.llama3-1-8b-instruct-v1:0": {
    "description": "Meta Llama 3.1 8B Instructの更新版で、拡張された128Kのコンテキスト長、多言語性、改善された推論能力を含んでいます。Llama 3.1が提供する多言語大型言語モデル（LLMs）は、8B、70B、405Bのサイズ（テキスト入力/出力）を含む一連の事前トレーニングされた、指示調整された生成モデルです。Llama 3.1の指示調整されたテキストモデル（8B、70B、405B）は、多言語対話用のユースケースに最適化されており、一般的な業界ベンチマークテストで多くの利用可能なオープンソースチャットモデルを超えています。Llama 3.1は多言語の商業および研究用途に使用されることを目的としています。指示調整されたテキストモデルはアシスタントのようなチャットに適しており、事前トレーニングモデルはさまざまな自然言語生成タスクに適応できます。Llama 3.1モデルは、他のモデルを改善するためにその出力を利用することもサポートしており、合成データ生成や精製を含みます。Llama 3.1は最適化されたトランスフォーマーアーキテクチャを使用した自己回帰型言語モデルです。調整版は、監視付き微調整（SFT）と人間のフィードバックを伴う強化学習（RLHF）を使用して、人間の助けや安全性に対する好みに適合させています。"
  },
  "meta.llama3-70b-instruct-v1:0": {
    "description": "Meta Llama 3は、開発者、研究者、企業向けのオープンな大規模言語モデル（LLM）であり、生成AIのアイデアを構築、実験、責任を持って拡張するのを支援することを目的としています。世界的なコミュニティの革新の基盤システムの一部として、コンテンツ作成、対話AI、言語理解、研究開発、企業アプリケーションに非常に適しています。"
  },
  "meta.llama3-8b-instruct-v1:0": {
    "description": "Meta Llama 3は、開発者、研究者、企業向けのオープンな大規模言語モデル（LLM）であり、生成AIのアイデアを構築、実験、責任を持って拡張するのを支援することを目的としています。世界的なコミュニティの革新の基盤システムの一部として、計算能力とリソースが限られたエッジデバイスや、より迅速なトレーニング時間に非常に適しています。"
  },
  "meta/llama-3.1-405b-instruct": {
    "description": "高度なLLMで、合成データ生成、知識蒸留、推論をサポートし、チャットボット、プログラミング、特定の分野のタスクに適しています。"
  },
  "meta/llama-3.1-70b-instruct": {
    "description": "複雑な対話を可能にし、卓越した文脈理解、推論能力、テキスト生成能力を備えています。"
  },
  "meta/llama-3.1-8b-instruct": {
    "description": "高度な最先端モデルで、言語理解、卓越した推論能力、テキスト生成能力を備えています。"
  },
  "meta/llama-3.2-11b-vision-instruct": {
    "description": "最先端の視覚-言語モデルで、画像から高品質な推論を行うのが得意です。"
  },
  "meta/llama-3.2-1b-instruct": {
    "description": "最先端の小型言語モデルで、言語理解、卓越した推論能力、テキスト生成能力を備えています。"
  },
  "meta/llama-3.2-3b-instruct": {
    "description": "最先端の小型言語モデルで、言語理解、卓越した推論能力、テキスト生成能力を備えています。"
  },
  "meta/llama-3.2-90b-vision-instruct": {
    "description": "最先端の視覚-言語モデルで、画像から高品質な推論を行うのが得意です。"
  },
  "meta/llama-3.3-70b-instruct": {
    "description": "高度なLLMで、推論、数学、常識、関数呼び出しに優れています。"
  },
  "microsoft/WizardLM-2-8x22B": {
    "description": "WizardLM 2はMicrosoft AIが提供する言語モデルで、複雑な対話、多言語、推論、インテリジェントアシスタントの分野で特に優れた性能を発揮します。"
  },
  "microsoft/wizardlm-2-8x22b": {
    "description": "WizardLM-2 8x22Bは、Microsoftの最先端AI Wizardモデルであり、非常に競争力のあるパフォーマンスを示しています。"
  },
  "minicpm-v": {
    "description": "MiniCPM-VはOpenBMBが発表した次世代のマルチモーダル大モデルで、優れたOCR認識能力とマルチモーダル理解能力を備え、幅広いアプリケーションシーンをサポートします。"
  },
  "ministral-3b-latest": {
    "description": "Ministral 3BはMistralの世界トップクラスのエッジモデルです。"
  },
  "ministral-8b-latest": {
    "description": "Ministral 8BはMistralのコストパフォーマンスに優れたエッジモデルです。"
  },
  "mistral": {
    "description": "Mistralは、Mistral AIがリリースした7Bモデルであり、多様な言語処理ニーズに適しています。"
  },
  "mistral-large": {
    "description": "Mixtral Largeは、Mistralのフラッグシップモデルであり、コード生成、数学、推論の能力を組み合わせ、128kのコンテキストウィンドウをサポートします。"
  },
  "mistral-large-latest": {
    "description": "Mistral Largeは、フラッグシップの大モデルであり、多言語タスク、複雑な推論、コード生成に優れ、高端アプリケーションに理想的な選択肢です。"
  },
  "mistral-nemo": {
    "description": "Mistral Nemoは、Mistral AIとNVIDIAが共同で開発した高効率の12Bモデルです。"
  },
  "mistral-small": {
    "description": "Mistral Smallは、高効率と低遅延を必要とする言語ベースのタスクで使用できます。"
  },
  "mistral-small-latest": {
    "description": "Mistral Smallは、コスト効率が高く、迅速かつ信頼性の高い選択肢で、翻訳、要約、感情分析などのユースケースに適しています。"
  },
  "mistralai/Mistral-7B-Instruct-v0.1": {
    "description": "Mistral (7B) Instructは、高性能で知られ、多言語タスクに適しています。"
  },
  "mistralai/Mistral-7B-Instruct-v0.2": {
    "description": "Mistral 7Bは、オンデマンドのファインチューニングモデルであり、タスクに最適化された解答を提供します。"
  },
  "mistralai/Mistral-7B-Instruct-v0.3": {
    "description": "Mistral (7B) Instruct v0.3は、高効率の計算能力と自然言語理解を提供し、幅広いアプリケーションに適しています。"
  },
  "mistralai/Mistral-7B-v0.1": {
    "description": "Mistral 7Bはコンパクトで高性能なモデルで、バッチ処理や分類、テキスト生成などの簡単なタスクに優れた推論能力を持っています。"
  },
  "mistralai/Mixtral-8x22B-Instruct-v0.1": {
    "description": "Mixtral-8x22B Instruct (141B)は、超大規模な言語モデルであり、非常に高い処理要求をサポートします。"
  },
  "mistralai/Mixtral-8x7B-Instruct-v0.1": {
    "description": "Mixtral 8x7Bは、一般的なテキストタスクに使用される事前訓練されたスパースミックス専門家モデルです。"
  },
  "mistralai/Mixtral-8x7B-v0.1": {
    "description": "Mixtral 8x7Bはスパースエキスパートモデルで、複数のパラメータを利用して推論速度を向上させ、多言語処理やコード生成タスクに適しています。"
  },
  "mistralai/mistral-7b-instruct": {
    "description": "Mistral 7B Instructは速度最適化と長いコンテキストサポートを兼ね備えた高性能な業界標準モデルです。"
  },
  "mistralai/mistral-nemo": {
    "description": "Mistral Nemoは多言語サポートと高性能プログラミングを備えた7.3Bパラメータモデルです。"
  },
  "mixtral": {
    "description": "Mixtralは、Mistral AIのエキスパートモデルであり、オープンソースの重みを持ち、コード生成と言語理解のサポートを提供します。"
  },
  "mixtral-8x7b-32768": {
    "description": "Mixtral 8x7Bは、高い耐障害性を持つ並列計算能力を提供し、複雑なタスクに適しています。"
  },
  "mixtral:8x22b": {
    "description": "Mixtralは、Mistral AIのエキスパートモデルであり、オープンソースの重みを持ち、コード生成と言語理解のサポートを提供します。"
  },
  "moonshot-v1-128k": {
    "description": "Moonshot V1 128Kは、超長いコンテキスト処理能力を持つモデルであり、超長文の生成に適しており、複雑な生成タスクのニーズを満たし、最大128,000トークンの内容を処理でき、研究、学術、大型文書生成などのアプリケーションシーンに非常に適しています。"
  },
  "moonshot-v1-128k-vision-preview": {
    "description": "Kimi視覚モデル（moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-previewなどを含む）は、画像の内容を理解でき、画像の文字、色、物体の形状などを含みます。"
  },
  "moonshot-v1-32k": {
    "description": "Moonshot V1 32Kは、中程度の長さのコンテキスト処理能力を提供し、32,768トークンを処理でき、さまざまな長文や複雑な対話の生成に特に適しており、コンテンツ作成、報告書生成、対話システムなどの分野で使用されます。"
  },
  "moonshot-v1-32k-vision-preview": {
    "description": "Kimi視覚モデル（moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-previewなどを含む）は、画像の内容を理解でき、画像の文字、色、物体の形状などを含みます。"
  },
  "moonshot-v1-8k": {
    "description": "Moonshot V1 8Kは、短文生成タスクのために設計されており、高効率な処理性能を持ち、8,192トークンを処理でき、短い対話、速記、迅速なコンテンツ生成に非常に適しています。"
  },
  "moonshot-v1-8k-vision-preview": {
    "description": "Kimi視覚モデル（moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-previewなどを含む）は、画像の内容を理解でき、画像の文字、色、物体の形状などを含みます。"
  },
  "moonshot-v1-auto": {
    "description": "Moonshot V1 Auto は、現在のコンテキストで使用されているトークンの数に基づいて適切なモデルを選択できます。"
  },
  "nousresearch/hermes-2-pro-llama-3-8b": {
    "description": "Hermes 2 Pro Llama 3 8BはNous Hermes 2のアップグレード版で、最新の内部開発データセットを含んでいます。"
  },
  "nvidia/Llama-3.1-Nemotron-70B-Instruct-HF": {
    "description": "Llama 3.1 Nemotron 70BはNVIDIAによってカスタマイズされた大規模言語モデルで、LLMが生成する応答がユーザーのクエリにどれだけ役立つかを向上させることを目的としています。このモデルはArena Hard、AlpacaEval 2 LC、GPT-4-Turbo MT-Benchなどのベンチマークテストで優れたパフォーマンスを示し、2024年10月1日現在、すべての自動整合ベンチマークテストで1位にランクされています。このモデルはRLHF（特にREINFORCE）、Llama-3.1-Nemotron-70B-Reward、HelpSteer2-Preferenceプロンプトを使用してLlama-3.1-70B-Instructモデルの基盤の上で訓練されています。"
  },
  "nvidia/llama-3.1-nemotron-51b-instruct": {
    "description": "独自の言語モデルで、比類のない精度と効率を提供します。"
  },
  "nvidia/llama-3.1-nemotron-70b-instruct": {
    "description": "Llama-3.1-Nemotron-70B-Instructは、NVIDIAがカスタマイズした大規模言語モデルで、LLMが生成する応答の有用性を向上させることを目的としています。"
  },
  "o1": {
    "description": "高度な推論と複雑な問題の解決に焦点を当てており、数学や科学のタスクを含みます。深いコンテキスト理解とエージェントワークフローを必要とするアプリケーションに非常に適しています。"
  },
  "o1-mini": {
    "description": "o1-miniは、プログラミング、数学、科学のアプリケーションシーンに特化して設計された迅速で経済的な推論モデルです。このモデルは128Kのコンテキストを持ち、2023年10月の知識のカットオフがあります。"
  },
  "o1-preview": {
    "description": "o1はOpenAIの新しい推論モデルで、広範な一般知識を必要とする複雑なタスクに適しています。このモデルは128Kのコンテキストを持ち、2023年10月の知識のカットオフがあります。"
  },
  "o3-mini": {
    "description": "o3-miniは、o1-miniと同じコストと遅延目標で高い知能を提供する最新の小型推論モデルです。"
  },
  "open-codestral-mamba": {
    "description": "Codestral Mambaは、コード生成に特化したMamba 2言語モデルであり、高度なコードおよび推論タスクを強力にサポートします。"
  },
  "open-mistral-7b": {
    "description": "Mistral 7Bは、コンパクトでありながら高性能なモデルであり、分類やテキスト生成などのバッチ処理や簡単なタスクに優れた推論能力を持っています。"
  },
  "open-mistral-nemo": {
    "description": "Mistral Nemoは、Nvidiaと共同開発された12Bモデルであり、優れた推論およびコーディング性能を提供し、統合と置き換えが容易です。"
  },
  "open-mixtral-8x22b": {
    "description": "Mixtral 8x22Bは、より大きなエキスパートモデルであり、複雑なタスクに特化し、優れた推論能力とより高いスループットを提供します。"
  },
  "open-mixtral-8x7b": {
    "description": "Mixtral 8x7Bは、スパースエキスパートモデルであり、複数のパラメータを利用して推論速度を向上させ、多言語およびコード生成タスクの処理に適しています。"
  },
  "openai/gpt-4o": {
    "description": "ChatGPT-4oは動的モデルで、最新のバージョンを維持するためにリアルタイムで更新されます。強力な言語理解と生成能力を組み合わせており、顧客サービス、教育、技術サポートなどの大規模なアプリケーションシナリオに適しています。"
  },
  "openai/gpt-4o-mini": {
    "description": "GPT-4o miniはOpenAIがGPT-4 Omniの後に発表した最新モデルで、画像とテキストの入力をサポートし、テキストを出力します。彼らの最先端の小型モデルとして、最近の他の最前線モデルよりもはるかに安価で、GPT-3.5 Turboよりも60%以上安価です。最先端の知能を維持しつつ、顕著なコストパフォーマンスを誇ります。GPT-4o miniはMMLUテストで82%のスコアを獲得し、現在チャットの好みでGPT-4よりも高い評価を得ています。"
  },
  "openai/o1-mini": {
    "description": "o1-miniは、プログラミング、数学、科学のアプリケーションシーンに特化して設計された迅速で経済的な推論モデルです。このモデルは128Kのコンテキストを持ち、2023年10月の知識のカットオフがあります。"
  },
  "openai/o1-preview": {
    "description": "o1はOpenAIの新しい推論モデルで、広範な一般知識を必要とする複雑なタスクに適しています。このモデルは128Kのコンテキストを持ち、2023年10月の知識のカットオフがあります。"
  },
  "openchat/openchat-7b": {
    "description": "OpenChat 7Bは「C-RLFT（条件強化学習微調整）」戦略で微調整されたオープンソース言語モデルライブラリです。"
  },
  "openrouter/auto": {
    "description": "コンテキストの長さ、テーマ、複雑さに応じて、あなたのリクエストはLlama 3 70B Instruct、Claude 3.5 Sonnet（自己調整）、またはGPT-4oに送信されます。"
  },
  "phi3": {
    "description": "Phi-3は、Microsoftが提供する軽量オープンモデルであり、高効率な統合と大規模な知識推論に適しています。"
  },
  "phi3:14b": {
    "description": "Phi-3は、Microsoftが提供する軽量オープンモデルであり、高効率な統合と大規模な知識推論に適しています。"
  },
  "pixtral-12b-2409": {
    "description": "Pixtralモデルは、グラフと画像理解、文書質問応答、多モーダル推論、指示遵守などのタスクで強力な能力を発揮し、自然な解像度とアスペクト比で画像を取り込み、最大128Kトークンの長いコンテキストウィンドウで任意の数の画像を処理できます。"
  },
  "pixtral-large-latest": {
    "description": "Pixtral Largeは、1240億のパラメータを持つオープンソースのマルチモーダルモデルで、Mistral Large 2に基づいて構築されています。これは私たちのマルチモーダルファミリーの中で2番目のモデルであり、最先端の画像理解能力を示しています。"
  },
  "pro-128k": {
    "description": "Spark Pro 128Kは特大のコンテキスト処理能力を備え、最大128Kのコンテキスト情報を処理できます。特に、全体を通じての分析や長期的な論理的関連性の処理が必要な長文コンテンツに適しており、複雑なテキストコミュニケーションにおいて滑らかで一貫した論理と多様な引用サポートを提供します。"
  },
  "qvq-72b-preview": {
    "description": "QVQモデルはQwenチームによって開発された実験的研究モデルで、視覚推論能力の向上に特化しており、特に数学推論の分野で優れた性能を発揮。"
  },
  "qwen-coder-plus-latest": {
    "description": "通義千問コードモデル。"
  },
  "qwen-coder-turbo-latest": {
    "description": "通義千問のコードモデルです。"
  },
  "qwen-long": {
    "description": "通義千問超大規模言語モデルで、長文コンテキストや長文書、複数文書に基づく対話機能をサポートしています。"
  },
  "qwen-math-plus-latest": {
    "description": "通義千問の数学モデルは、数学の問題解決に特化した言語モデルです。"
  },
  "qwen-math-turbo-latest": {
    "description": "通義千問の数学モデルは、数学の問題解決に特化した言語モデルです。"
  },
  "qwen-max": {
    "description": "通義千問の千億レベルの超大規模言語モデルで、中国語、英語などさまざまな言語の入力をサポートしています。現在、通義千問2.5製品バージョンの背後にあるAPIモデルです。"
  },
  "qwen-max-latest": {
    "description": "通義千問の千億レベルの超大規模言語モデルで、中国語、英語などの異なる言語入力をサポートし、現在の通義千問2.5製品バージョンの背後にあるAPIモデルです。"
  },
  "qwen-plus": {
    "description": "通義千問の超大規模言語モデルの強化版で、中国語、英語などさまざまな言語の入力をサポートしています。"
  },
  "qwen-plus-latest": {
    "description": "通義千問の超大規模言語モデルの強化版で、中国語、英語などの異なる言語入力をサポートしています。"
  },
  "qwen-turbo": {
    "description": "通義千問の超大規模言語モデルで、中国語、英語などさまざまな言語の入力をサポートしています。"
  },
  "qwen-turbo-latest": {
    "description": "通義千問の超大規模言語モデルで、中国語、英語などの異なる言語入力をサポートしています。"
  },
  "qwen-vl-chat-v1": {
    "description": "通義千問VLは、複数の画像、多段階の質問応答、創作などの柔軟なインタラクション方式をサポートするモデルです。"
  },
  "qwen-vl-max-latest": {
    "description": "通義千問の超大規模視覚言語モデル。強化版に比べて、視覚推論能力と指示遵守能力をさらに向上させ、より高い視覚認識と認知レベルを提供します。"
  },
  "qwen-vl-ocr-latest": {
    "description": "通義千問OCRは、文書、表、試験問題、手書き文字などの画像から文字を抽出する専用モデルです。多様な文字を認識でき、現在サポートされている言語は中国語、英語、フランス語、日本語、韓国語、ドイツ語、ロシア語、イタリア語、ベトナム語、アラビア語です。"
  },
  "qwen-vl-plus-latest": {
    "description": "通義千問の大規模視覚言語モデルの強化版。詳細認識能力と文字認識能力を大幅に向上させ、100万ピクセル以上の解像度と任意のアスペクト比の画像をサポートします。"
  },
  "qwen-vl-v1": {
    "description": "Qwen-7B言語モデルを初期化し、画像モデルを追加した、画像入力解像度448の事前トレーニングモデルです。"
  },
  "qwen/qwen-2-7b-instruct:free": {
    "description": "Qwen2は全く新しい大型言語モデルシリーズで、より強力な理解と生成能力を備えています。"
  },
  "qwen/qwen2.5-7b-instruct": {
    "description": "中国語と英語に対応したLLMで、言語、プログラミング、数学、推論などの分野に特化しています。"
  },
  "qwen/qwen2.5-coder-32b-instruct": {
    "description": "高度なLLMで、コード生成、推論、修正をサポートし、主流のプログラミング言語をカバーしています。"
  },
  "qwen/qwen2.5-coder-7b-instruct": {
    "description": "強力な中型コードモデルで、32Kのコンテキスト長をサポートし、多言語プログラミングに優れています。"
  },
  "qwen2": {
    "description": "Qwen2は、Alibabaの新世代大規模言語モデルであり、優れた性能で多様なアプリケーションニーズをサポートします。"
  },
  "qwen2.5": {
    "description": "Qwen2.5はAlibabaの次世代大規模言語モデルで、優れた性能を持ち、多様なアプリケーションのニーズをサポートします。"
  },
  "qwen2.5-14b-instruct": {
    "description": "通義千問2.5の対外オープンソースの14B規模のモデルです。"
  },
  "qwen2.5-14b-instruct-1m": {
    "description": "通義千問2.5が公開した72B規模のモデルです。"
  },
  "qwen2.5-32b-instruct": {
    "description": "通義千問2.5の対外オープンソースの32B規模のモデルです。"
  },
  "qwen2.5-72b-instruct": {
    "description": "通義千問2.5の対外オープンソースの72B規模のモデルです。"
  },
  "qwen2.5-7b-instruct": {
    "description": "通義千問2.5の対外オープンソースの7B規模のモデルです。"
  },
  "qwen2.5-coder-1.5b-instruct": {
    "description": "通義千問コードモデルのオープンソース版です。"
  },
  "qwen2.5-coder-32b-instruct": {
    "description": "通義千問コードモデルのオープンソース版。"
  },
  "qwen2.5-coder-7b-instruct": {
    "description": "通義千問のコードモデルのオープンソース版です。"
  },
  "qwen2.5-math-1.5b-instruct": {
    "description": "Qwen-Mathモデルは、強力な数学的問題解決能力を備えています。"
  },
  "qwen2.5-math-72b-instruct": {
    "description": "Qwen-Mathモデルは、強力な数学の問題解決能力を持っています。"
  },
  "qwen2.5-math-7b-instruct": {
    "description": "Qwen-Mathモデルは、強力な数学の問題解決能力を持っています。"
  },
  "qwen2.5-vl-72b-instruct": {
    "description": "指示に従い、数学、問題解決、コード全体の向上、万物認識能力の向上を実現し、多様な形式で視覚要素を直接的に正確に特定し、長い動画ファイル（最大10分）を理解し、秒単位のイベント時刻を特定でき、時間の前後や速さを理解し、解析と特定能力に基づいてOSやモバイルのエージェントを操作し、重要な情報抽出能力とJson形式出力能力が強化されています。このバージョンは72Bバージョンで、本シリーズの中で最も強力なバージョンです。"
  },
  "qwen2.5-vl-7b-instruct": {
    "description": "指示に従い、数学、問題解決、コード全体の向上、万物認識能力の向上を実現し、多様な形式で視覚要素を直接的に正確に特定し、長い動画ファイル（最大10分）を理解し、秒単位のイベント時刻を特定でき、時間の前後や速さを理解し、解析と特定能力に基づいてOSやモバイルのエージェントを操作し、重要な情報抽出能力とJson形式出力能力が強化されています。このバージョンは72Bバージョンで、本シリーズの中で最も強力なバージョンです。"
  },
  "qwen2.5:0.5b": {
    "description": "Qwen2.5はAlibabaの次世代大規模言語モデルで、優れた性能を持ち、多様なアプリケーションのニーズをサポートします。"
  },
  "qwen2.5:1.5b": {
    "description": "Qwen2.5はAlibabaの次世代大規模言語モデルで、優れた性能を持ち、多様なアプリケーションのニーズをサポートします。"
  },
  "qwen2.5:72b": {
    "description": "Qwen2.5はAlibabaの次世代大規模言語モデルで、優れた性能を持ち、多様なアプリケーションのニーズをサポートします。"
  },
  "qwen2:0.5b": {
    "description": "Qwen2は、Alibabaの新世代大規模言語モデルであり、優れた性能で多様なアプリケーションニーズをサポートします。"
  },
  "qwen2:1.5b": {
    "description": "Qwen2は、Alibabaの新世代大規模言語モデルであり、優れた性能で多様なアプリケーションニーズをサポートします。"
  },
  "qwen2:72b": {
    "description": "Qwen2は、Alibabaの新世代大規模言語モデルであり、優れた性能で多様なアプリケーションニーズをサポートします。"
  },
  "qwq": {
    "description": "QwQはAIの推論能力を向上させることに特化した実験的研究モデルです。"
  },
  "qwq-32b-preview": {
    "description": "QwQモデルはQwenチームによって開発された実験的な研究モデルで、AIの推論能力を強化することに焦点を当てています。"
  },
  "solar-mini": {
    "description": "Solar MiniはコンパクトなLLMで、GPT-3.5を上回る性能を持ち、強力な多言語能力を備え、英語と韓国語をサポートし、高効率でコンパクトなソリューションを提供します。"
  },
  "solar-mini-ja": {
    "description": "Solar Mini (Ja) はSolar Miniの能力を拡張し、日本語に特化しながら、英語と韓国語の使用においても高効率で卓越した性能を維持しています。"
  },
  "solar-pro": {
    "description": "Solar ProはUpstageが発表した高インテリジェンスLLMで、単一GPUの指示追従能力に特化しており、IFEvalスコアは80以上です。現在は英語をサポートしており、正式版は2024年11月にリリース予定で、言語サポートとコンテキスト長を拡張します。"
  },
  "sonar": {
    "description": "検索コンテキストに基づく軽量検索製品で、Sonar Proよりも速く、安価です。"
  },
  "sonar-pro": {
    "description": "検索コンテキストをサポートする高度な検索製品で、高度なクエリとフォローアップをサポートします。"
  },
  "sonar-reasoning": {
    "description": "DeepSeek推論モデルによってサポートされる新しいAPI製品です。"
  },
  "sonar-reasoning-pro": {
    "description": "DeepSeek推論モデルによってサポートされる新しいAPI製品。"
  },
  "step-1-128k": {
    "description": "性能とコストのバランスを取り、一般的なシナリオに適しています。"
  },
  "step-1-256k": {
    "description": "超長コンテキスト処理能力を持ち、特に長文書分析に適しています。"
  },
  "step-1-32k": {
    "description": "中程度の長さの対話をサポートし、さまざまなアプリケーションシナリオに適しています。"
  },
  "step-1-8k": {
    "description": "小型モデルであり、軽量なタスクに適しています。"
  },
  "step-1-flash": {
    "description": "高速モデルであり、リアルタイムの対話に適しています。"
  },
  "step-1.5v-mini": {
    "description": "このモデルは、強力なビデオ理解能力を備えています。"
  },
  "step-1o-turbo-vision": {
    "description": "このモデルは強力な画像理解能力を持ち、数理、コード分野で1oより優れています。モデルは1oよりも小さく、出力速度が速くなっています。"
  },
  "step-1o-vision-32k": {
    "description": "このモデルは強力な画像理解能力を持っています。step-1vシリーズモデルと比較して、より優れた視覚性能を発揮します。"
  },
  "step-1v-32k": {
    "description": "視覚入力をサポートし、多モーダルインタラクション体験を強化します。"
  },
  "step-1v-8k": {
    "description": "小型ビジュアルモデルで、基本的なテキストと画像のタスクに適しています。"
  },
  "step-2-16k": {
    "description": "大規模なコンテキストインタラクションをサポートし、複雑な対話シナリオに適しています。"
  },
  "step-2-mini": {
    "description": "新世代の自社開発のAttentionアーキテクチャMFAに基づく超高速大モデルで、非常に低コストでstep1と同様の効果を達成しつつ、より高いスループットと迅速な応答遅延を維持しています。一般的なタスクを処理でき、コード能力において特長を持っています。"
  },
  "taichu_llm": {
    "description": "紫東太初言語大モデルは、強力な言語理解能力とテキスト創作、知識問答、コードプログラミング、数学計算、論理推論、感情分析、テキスト要約などの能力を備えています。革新的に大データの事前学習と多源の豊富な知識を組み合わせ、アルゴリズム技術を継続的に磨き、膨大なテキストデータから語彙、構造、文法、意味などの新しい知識を吸収し、モデルの効果を進化させています。ユーザーにより便利な情報とサービス、よりインテリジェントな体験を提供します。"
  },
  "taichu_vl": {
    "description": "画像理解、知識移転、論理帰納などの能力を融合し、画像とテキストの質問応答分野で優れたパフォーマンスを発揮します。"
  },
  "text-embedding-3-large": {
    "description": "最も強力なベクトル化モデル、英語および非英語のタスクに適しています"
  },
  "text-embedding-3-small": {
    "description": "効率的で経済的な次世代埋め込みモデル、知識検索やRAGアプリケーションなどのシーンに適しています"
  },
  "togethercomputer/StripedHyena-Nous-7B": {
    "description": "StripedHyena Nous (7B)は、高効率の戦略とモデルアーキテクチャを通じて、強化された計算能力を提供します。"
  },
  "tts-1": {
    "description": "最新のテキスト音声合成モデル、リアルタイムシーン向けに速度を最適化"
  },
  "tts-1-hd": {
    "description": "最新のテキスト音声合成モデル、品質を最適化"
  },
  "upstage/SOLAR-10.7B-Instruct-v1.0": {
    "description": "Upstage SOLAR Instruct v1 (11B)は、精密な指示タスクに適しており、優れた言語処理能力を提供します。"
  },
  "us.anthropic.claude-3-5-sonnet-20241022-v2:0": {
    "description": "Claude 3.5 Sonnetは業界標準を向上させ、競合モデルやClaude 3 Opusを超える性能を持ち、広範な評価で優れた結果を示し、我々の中程度のモデルの速度とコストを兼ね備えています。"
  },
  "whisper-1": {
    "description": "汎用音声認識モデル、多言語音声認識、音声翻訳、言語認識をサポート"
  },
  "wizardlm2": {
    "description": "WizardLM 2は、Microsoft AIが提供する言語モデルであり、複雑な対話、多言語、推論、インテリジェントアシスタントの分野で特に優れた性能を発揮します。"
  },
  "wizardlm2:8x22b": {
    "description": "WizardLM 2は、Microsoft AIが提供する言語モデルであり、複雑な対話、多言語、推論、インテリジェントアシスタントの分野で特に優れた性能を発揮します。"
  },
  "yi-large": {
    "description": "新しい千億パラメータモデルであり、超強力な質問応答およびテキスト生成能力を提供します。"
  },
  "yi-large-fc": {
    "description": "yi-largeモデルを基に、ツール呼び出しの能力をサポートし強化し、エージェントやワークフローを構築する必要があるさまざまなビジネスシナリオに適しています。"
  },
  "yi-large-preview": {
    "description": "初期バージョンであり、yi-large（新バージョン）の使用を推奨します。"
  },
  "yi-large-rag": {
    "description": "yi-largeの超強力モデルに基づく高次サービスであり、検索と生成技術を組み合わせて正確な回答を提供し、リアルタイムで全網検索情報サービスを提供します。"
  },
  "yi-large-turbo": {
    "description": "超高コストパフォーマンス、卓越した性能。性能と推論速度、コストに基づいて、高精度のバランス調整を行います。"
  },
  "yi-lightning": {
    "description": "最新の高性能モデルで、高品質な出力を保証しつつ、推論速度が大幅に向上しています。"
  },
  "yi-lightning-lite": {
    "description": "軽量版で、yi-lightningの使用を推奨します。"
  },
  "yi-medium": {
    "description": "中型サイズモデルのアップグレード微調整であり、能力が均衡しており、コストパフォーマンスが高いです。指示遵守能力を深く最適化しています。"
  },
  "yi-medium-200k": {
    "description": "200Kの超長コンテキストウィンドウを持ち、長文の深い理解と生成能力を提供します。"
  },
  "yi-spark": {
    "description": "小型で強力な、軽量で高速なモデルです。強化された数学演算とコード作成能力を提供します。"
  },
  "yi-vision": {
    "description": "複雑な視覚タスクモデルであり、高性能な画像理解と分析能力を提供します。"
  },
  "yi-vision-v2": {
    "description": "複雑な視覚タスクモデルで、複数の画像に基づく高性能な理解と分析能力を提供します。"
  }
}
